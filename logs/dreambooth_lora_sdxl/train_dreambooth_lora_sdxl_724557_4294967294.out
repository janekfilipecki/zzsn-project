05/21/2024 16:40:09 - INFO - __main__ - Distributed environment: DistributedType.NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda

Mixed precision type: no

Fetching 19 files:   0%|          | 0/19 [00:00<?, ?it/s]Fetching 19 files:  11%|█         | 2/19 [00:00<00:02,  6.45it/s]Fetching 19 files:  16%|█▌        | 3/19 [00:00<00:02,  5.59it/s]Fetching 19 files:  21%|██        | 4/19 [00:25<02:23,  9.57s/it]Fetching 19 files:  32%|███▏      | 6/19 [01:21<04:05, 18.92s/it]Fetching 19 files:  84%|████████▍ | 16/19 [04:53<01:02, 20.75s/it]Fetching 19 files: 100%|██████████| 19/19 [04:53<00:00, 15.46s/it]
{'feature_extractor', 'image_encoder'} was not found in config. Values will be initialized to default values.
Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]{'reverse_transformer_layers_per_block', 'attention_type', 'dropout'} was not found in config. Values will be initialized to default values.
Loaded unet as UNet2DConditionModel from `unet` subfolder of stabilityai/stable-diffusion-xl-base-1.0.
Loading pipeline components...:  14%|█▍        | 1/7 [00:09<00:57,  9.60s/it]Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of stabilityai/stable-diffusion-xl-base-1.0.
Loading pipeline components...:  29%|██▊       | 2/7 [00:09<00:20,  4.04s/it]Loaded tokenizer_2 as CLIPTokenizer from `tokenizer_2` subfolder of stabilityai/stable-diffusion-xl-base-1.0.
Loaded text_encoder_2 as CLIPTextModelWithProjection from `text_encoder_2` subfolder of stabilityai/stable-diffusion-xl-base-1.0.
Loading pipeline components...:  57%|█████▋    | 4/7 [00:12<00:07,  2.35s/it]{'sigma_min', 'timestep_type', 'sigma_max', 'final_sigmas_type', 'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.
Loaded scheduler as EulerDiscreteScheduler from `scheduler` subfolder of stabilityai/stable-diffusion-xl-base-1.0.
{'latents_std', 'latents_mean'} was not found in config. Values will be initialized to default values.
Loaded vae as AutoencoderKL from `vae` subfolder of stabilityai/stable-diffusion-xl-base-1.0.
Loading pipeline components...:  86%|████████▌ | 6/7 [00:12<00:01,  1.33s/it]Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of stabilityai/stable-diffusion-xl-base-1.0.
Loading pipeline components...: 100%|██████████| 7/7 [00:13<00:00,  1.18s/it]Loading pipeline components...: 100%|██████████| 7/7 [00:13<00:00,  1.94s/it]
05/21/2024 16:45:17 - INFO - __main__ - Number of class images to sample: 200.
Generating class images:   0%|          | 0/50 [00:00<?, ?it/s]Generating class images:   2%|▏         | 1/50 [00:22<18:19, 22.44s/it]Generating class images:   4%|▍         | 2/50 [00:43<17:08, 21.43s/it]Generating class images:   6%|▌         | 3/50 [01:03<16:32, 21.12s/it]Generating class images:   8%|▊         | 4/50 [01:24<16:05, 20.99s/it]Generating class images:  10%|█         | 5/50 [01:45<15:41, 20.93s/it]Generating class images:  12%|█▏        | 6/50 [02:06<15:19, 20.89s/it]Generating class images:  14%|█▍        | 7/50 [02:27<14:56, 20.85s/it]Generating class images:  16%|█▌        | 8/50 [02:47<14:35, 20.84s/it]Generating class images:  18%|█▊        | 9/50 [03:08<14:14, 20.84s/it]Generating class images:  20%|██        | 10/50 [03:29<13:52, 20.82s/it]Generating class images:  22%|██▏       | 11/50 [03:50<13:31, 20.81s/it]Generating class images:  24%|██▍       | 12/50 [04:11<13:10, 20.81s/it]Generating class images:  26%|██▌       | 13/50 [04:31<12:49, 20.80s/it]Generating class images:  28%|██▊       | 14/50 [04:52<12:29, 20.81s/it]Generating class images:  30%|███       | 15/50 [05:13<12:08, 20.81s/it]Generating class images:  32%|███▏      | 16/50 [05:34<11:47, 20.81s/it]Generating class images:  34%|███▍      | 17/50 [05:55<11:27, 20.82s/it]Generating class images:  36%|███▌      | 18/50 [06:16<11:05, 20.81s/it]Generating class images:  38%|███▊      | 19/50 [06:36<10:45, 20.82s/it]Generating class images:  40%|████      | 20/50 [06:57<10:24, 20.82s/it]Generating class images:  42%|████▏     | 21/50 [07:18<10:04, 20.83s/it]Generating class images:  44%|████▍     | 22/50 [07:39<09:43, 20.84s/it]Generating class images:  46%|████▌     | 23/50 [08:00<09:22, 20.84s/it]Generating class images:  48%|████▊     | 24/50 [08:21<09:01, 20.84s/it]Generating class images:  50%|█████     | 25/50 [08:41<08:40, 20.84s/it]Generating class images:  52%|█████▏    | 26/50 [09:02<08:19, 20.83s/it]Generating class images:  54%|█████▍    | 27/50 [09:23<07:59, 20.83s/it]Generating class images:  56%|█████▌    | 28/50 [09:44<07:38, 20.83s/it]Generating class images:  58%|█████▊    | 29/50 [10:05<07:17, 20.83s/it]Generating class images:  60%|██████    | 30/50 [10:26<06:56, 20.83s/it]Generating class images:  62%|██████▏   | 31/50 [10:46<06:35, 20.82s/it]Generating class images:  64%|██████▍   | 32/50 [11:07<06:14, 20.82s/it]Generating class images:  66%|██████▌   | 33/50 [11:28<05:54, 20.83s/it]Generating class images:  68%|██████▊   | 34/50 [11:49<05:33, 20.83s/it]Generating class images:  70%|███████   | 35/50 [12:10<05:12, 20.83s/it]Generating class images:  72%|███████▏  | 36/50 [12:30<04:51, 20.83s/it]Generating class images:  74%|███████▍  | 37/50 [12:51<04:30, 20.83s/it]Generating class images:  76%|███████▌  | 38/50 [13:12<04:09, 20.83s/it]Generating class images:  78%|███████▊  | 39/50 [13:33<03:49, 20.82s/it]Generating class images:  80%|████████  | 40/50 [13:54<03:28, 20.83s/it]Generating class images:  82%|████████▏ | 41/50 [14:15<03:07, 20.83s/it]Generating class images:  84%|████████▍ | 42/50 [14:35<02:46, 20.83s/it]Generating class images:  86%|████████▌ | 43/50 [14:56<02:25, 20.81s/it]Generating class images:  88%|████████▊ | 44/50 [15:17<02:04, 20.82s/it]Generating class images:  90%|█████████ | 45/50 [15:38<01:44, 20.82s/it]Generating class images:  92%|█████████▏| 46/50 [15:59<01:23, 20.82s/it]Generating class images:  94%|█████████▍| 47/50 [16:19<01:02, 20.81s/it]Generating class images:  96%|█████████▌| 48/50 [16:40<00:41, 20.81s/it]Generating class images:  98%|█████████▊| 49/50 [17:01<00:20, 20.80s/it]Generating class images: 100%|██████████| 50/50 [17:22<00:00, 20.81s/it]Generating class images: 100%|██████████| 50/50 [17:22<00:00, 20.85s/it]
You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.
You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.
{'clip_sample_range', 'dynamic_thresholding_ratio', 'variance_type', 'thresholding', 'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.
{'latents_std', 'latents_mean'} was not found in config. Values will be initialized to default values.
{'reverse_transformer_layers_per_block', 'attention_type', 'dropout'} was not found in config. Values will be initialized to default values.
Traceback (most recent call last):
  File "/net/tscratch/people/plgas2000/zzsn-project/train_dreambooth_lora_sdxl.py", line 1984, in <module>
    main(args)
  File "/net/tscratch/people/plgas2000/zzsn-project/train_dreambooth_lora_sdxl.py", line 1415, in main
    train_dataset = DreamBoothDataset(
                    ^^^^^^^^^^^^^^^^^^
  File "/net/tscratch/people/plgas2000/zzsn-project/train_dreambooth_lora_sdxl.py", line 778, in __init__
    raise ValueError("Instance images root doesn't exists.")
ValueError: Instance images root doesn't exists.
Traceback (most recent call last):
  File "/net/tscratch/people/plgas2000/.conda/envs/env_zzsn/bin/accelerate", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/net/tscratch/people/plgas2000/.conda/envs/env_zzsn/lib/python3.12/site-packages/accelerate/commands/accelerate_cli.py", line 46, in main
    args.func(args)
  File "/net/tscratch/people/plgas2000/.conda/envs/env_zzsn/lib/python3.12/site-packages/accelerate/commands/launch.py", line 1075, in launch_command
    simple_launcher(args)
  File "/net/tscratch/people/plgas2000/.conda/envs/env_zzsn/lib/python3.12/site-packages/accelerate/commands/launch.py", line 681, in simple_launcher
    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)
subprocess.CalledProcessError: Command '['/net/tscratch/people/plgas2000/.conda/envs/env_zzsn/bin/python', 'train_dreambooth_lora_sdxl.py', '--pretrained_model_name_or_path=stabilityai/stable-diffusion-xl-base-1.0', '--instance_data_dir=./dataset/dreambooth-main/dataset/dog6', '--class_data_dir=./dataset/dreambooth_generated/dog', '--output_dir=./models/dreambooth_lora_sdxl_dog6', '--pretrained_vae_model_name_or_path=madebyollin/sdxl-vae-fp16-fix', '--with_prior_preservation', '--prior_loss_weight=1.0', '--instance_prompt=a sks dog', '--class_prompt=a dog', '--resolution=512', '--train_batch_size=1', '--gradient_accumulation_steps=1', '--learning_rate=5e-6', '--lr_scheduler=constant', '--lr_warmup_steps=0', '--num_class_images=200', '--max_train_steps=800', '--logging_dir=./logs/tensorboard_logs', '--report_to=tensorboard']' returned non-zero exit status 1.
