The following values were not passed to `accelerate launch` and had defaults used instead:
	`--num_processes` was set to a value of `1`
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
/net/tscratch/people/plgas2000/.conda/envs/myenv2/lib/python3.9/site-packages/diffusers/utils/outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
  torch.utils._pytree._register_pytree_node(
06/11/2024 15:12:47 - INFO - __main__ - Distributed environment: NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda

Mixed precision type: fp16

You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.
You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.
/net/tscratch/people/plgas2000/.conda/envs/myenv2/lib/python3.9/site-packages/diffusers/utils/outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
  torch.utils._pytree._register_pytree_node(
{'variance_type', 'dynamic_thresholding_ratio', 'thresholding', 'clip_sample_range'} was not found in config. Values will be initialized to default values.
{'attention_type', 'dropout', 'reverse_transformer_layers_per_block'} was not found in config. Values will be initialized to default values.
06/11/2024 15:13:20 - INFO - __main__ - Number of Trainable Parameters: 1.57 M
wandb: Currently logged in as: salbowic (salbowic-org). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.17.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in /net/tscratch/people/plgas2000/zzsn-project/wandb/run-20240611_151323-nz37yu6d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-valley-14
wandb: ‚≠êÔ∏è View project at https://wandb.ai/salbowic-org/dreambooth-ziplora-sd-xl
wandb: üöÄ View run at https://wandb.ai/salbowic-org/dreambooth-ziplora-sd-xl/runs/nz37yu6d
06/11/2024 15:13:27 - INFO - __main__ - ***** Running training *****
06/11/2024 15:13:27 - INFO - __main__ -   Num examples = 7
06/11/2024 15:13:27 - INFO - __main__ -   Num batches each epoch = 7
06/11/2024 15:13:27 - INFO - __main__ -   Num Epochs = 15
06/11/2024 15:13:27 - INFO - __main__ -   Instantaneous batch size per device = 1
06/11/2024 15:13:27 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 1
06/11/2024 15:13:27 - INFO - __main__ -   Gradient Accumulation steps = 1
06/11/2024 15:13:27 - INFO - __main__ -   Total optimization steps = 100
Steps:   0%|          | 0/100 [00:00<?, ?it/s]Steps:   1%|          | 1/100 [00:03<06:11,  3.75s/it]Steps:   1%|          | 1/100 [00:03<06:11,  3.75s/it, loss=5.6, loss_1=0.000179, loss_2=0.000379, loss_3=5.6, lr=5e-5]Steps:   2%|‚ñè         | 2/100 [00:06<04:52,  2.99s/it, loss=5.6, loss_1=0.000179, loss_2=0.000379, loss_3=5.6, lr=5e-5]Steps:   2%|‚ñè         | 2/100 [00:06<04:52,  2.99s/it, loss=5.6, loss_1=0.00159, loss_2=0.00391, loss_3=5.6, lr=5e-5]  Steps:   3%|‚ñé         | 3/100 [00:08<04:20,  2.68s/it, loss=5.6, loss_1=0.00159, loss_2=0.00391, loss_3=5.6, lr=5e-5]Steps:   3%|‚ñé         | 3/100 [00:08<04:20,  2.68s/it, loss=5.6, loss_1=0.000222, loss_2=0.000557, loss_3=5.6, lr=5e-5]Steps:   4%|‚ñç         | 4/100 [00:10<04:08,  2.59s/it, loss=5.6, loss_1=0.000222, loss_2=0.000557, loss_3=5.6, lr=5e-5]Steps:   4%|‚ñç         | 4/100 [00:10<04:08,  2.59s/it, loss=5.6, loss_1=0.00112, loss_2=0.00244, loss_3=5.6, lr=5e-5]  Steps:   5%|‚ñå         | 5/100 [00:13<03:57,  2.49s/it, loss=5.6, loss_1=0.00112, loss_2=0.00244, loss_3=5.6, lr=5e-5]Steps:   5%|‚ñå         | 5/100 [00:13<03:57,  2.49s/it, loss=5.6, loss_1=2.54e-5, loss_2=3.39e-5, loss_3=5.6, lr=5e-5]Steps:   6%|‚ñå         | 6/100 [00:15<03:52,  2.48s/it, loss=5.6, loss_1=2.54e-5, loss_2=3.39e-5, loss_3=5.6, lr=5e-5]Steps:   6%|‚ñå         | 6/100 [00:15<03:52,  2.48s/it, loss=5.6, loss_1=0.000216, loss_2=0.000101, loss_3=5.6, lr=5e-5]Steps:   7%|‚ñã         | 7/100 [00:18<03:44,  2.41s/it, loss=5.6, loss_1=0.000216, loss_2=0.000101, loss_3=5.6, lr=5e-5]Steps:   7%|‚ñã         | 7/100 [00:18<03:44,  2.41s/it, loss=5.6, loss_1=0.00237, loss_2=0.00259, loss_3=5.6, lr=5e-5]  06/11/2024 15:13:45 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: a sbu dog in the crt style.
{'image_encoder', 'feature_extractor'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][ALoaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of stabilityai/stable-diffusion-xl-base-1.0.
{'sigma_min', 'timestep_type', 'sigma_max'} was not found in config. Values will be initialized to default values.
Loaded scheduler as EulerDiscreteScheduler from `scheduler` subfolder of stabilityai/stable-diffusion-xl-base-1.0.
Loaded tokenizer_2 as CLIPTokenizer from `tokenizer_2` subfolder of stabilityai/stable-diffusion-xl-base-1.0.

Loading pipeline components...:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:00<00:00, 41.13it/s][ALoading pipeline components...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 57.29it/s]
{'solver_order', 'variance_type', 'dynamic_thresholding_ratio', 'thresholding', 'lambda_min_clipped', 'euler_at_final', 'solver_type', 'use_lu_lambdas', 'algorithm_type', 'lower_order_final'} was not found in config. Values will be initialized to default values.
Steps:   8%|‚ñä         | 8/100 [01:11<28:34, 18.63s/it, loss=5.6, loss_1=0.00237, loss_2=0.00259, loss_3=5.6, lr=5e-5]Steps:   8%|‚ñä         | 8/100 [01:11<28:34, 18.63s/it, loss=5.6, loss_1=3.75e-5, loss_2=2.98e-5, loss_3=5.6, lr=5e-5]Steps:   9%|‚ñâ         | 9/100 [01:13<20:35, 13.57s/it, loss=5.6, loss_1=3.75e-5, loss_2=2.98e-5, loss_3=5.6, lr=5e-5]Steps:   9%|‚ñâ         | 9/100 [01:13<20:35, 13.57s/it, loss=5.6, loss_1=0.0032, loss_2=0.00205, loss_3=5.6, lr=5e-5] Steps:  10%|‚ñà         | 10/100 [01:16<15:09, 10.10s/it, loss=5.6, loss_1=0.0032, loss_2=0.00205, loss_3=5.6, lr=5e-5]Steps:  10%|‚ñà         | 10/100 [01:16<15:09, 10.10s/it, loss=5.6, loss_1=0.00308, loss_2=0.00168, loss_3=5.59, lr=5e-5]Steps:  11%|‚ñà         | 11/100 [01:18<11:30,  7.76s/it, loss=5.6, loss_1=0.00308, loss_2=0.00168, loss_3=5.59, lr=5e-5]Steps:  11%|‚ñà         | 11/100 [01:18<11:30,  7.76s/it, loss=5.6, loss_1=0.00205, loss_2=0.00331, loss_3=5.59, lr=5e-5]Steps:  12%|‚ñà‚ñè        | 12/100 [01:20<08:57,  6.11s/it, loss=5.6, loss_1=0.00205, loss_2=0.00331, loss_3=5.59, lr=5e-5]Steps:  12%|‚ñà‚ñè        | 12/100 [01:20<08:57,  6.11s/it, loss=5.6, loss_1=0.000714, loss_2=0.00156, loss_3=5.59, lr=5e-5]Steps:  13%|‚ñà‚ñé        | 13/100 [01:23<07:14,  5.00s/it, loss=5.6, loss_1=0.000714, loss_2=0.00156, loss_3=5.59, lr=5e-5]Steps:  13%|‚ñà‚ñé        | 13/100 [01:23<07:14,  5.00s/it, loss=5.6, loss_1=0.00103, loss_2=0.00161, loss_3=5.59, lr=5e-5] Steps:  14%|‚ñà‚ñç        | 14/100 [01:25<05:59,  4.18s/it, loss=5.6, loss_1=0.00103, loss_2=0.00161, loss_3=5.59, lr=5e-5]Steps:  14%|‚ñà‚ñç        | 14/100 [01:25<05:59,  4.18s/it, loss=5.6, loss_1=0.00111, loss_2=0.00253, loss_3=5.59, lr=5e-5]Steps:  15%|‚ñà‚ñå        | 15/100 [01:28<05:12,  3.67s/it, loss=5.6, loss_1=0.00111, loss_2=0.00253, loss_3=5.59, lr=5e-5]Steps:  15%|‚ñà‚ñå        | 15/100 [01:28<05:12,  3.67s/it, loss=5.6, loss_1=0.00118, loss_2=0.00239, loss_3=5.59, lr=5e-5]Steps:  16%|‚ñà‚ñå        | 16/100 [01:30<04:37,  3.31s/it, loss=5.6, loss_1=0.00118, loss_2=0.00239, loss_3=5.59, lr=5e-5]Steps:  16%|‚ñà‚ñå        | 16/100 [01:30<04:37,  3.31s/it, loss=5.59, loss_1=0.000344, loss_2=0.000698, loss_3=5.59, lr=5e-5]Steps:  17%|‚ñà‚ñã        | 17/100 [01:32<04:09,  3.01s/it, loss=5.59, loss_1=0.000344, loss_2=0.000698, loss_3=5.59, lr=5e-5]Steps:  17%|‚ñà‚ñã        | 17/100 [01:32<04:09,  3.01s/it, loss=5.6, loss_1=0.00249, loss_2=0.00275, loss_3=5.59, lr=5e-5]   Steps:  18%|‚ñà‚ñä        | 18/100 [01:35<03:53,  2.84s/it, loss=5.6, loss_1=0.00249, loss_2=0.00275, loss_3=5.59, lr=5e-5]Steps:  18%|‚ñà‚ñä        | 18/100 [01:35<03:53,  2.84s/it, loss=5.59, loss_1=0.000116, loss_2=0.000589, loss_3=5.59, lr=5e-5]Steps:  19%|‚ñà‚ñâ        | 19/100 [01:37<03:37,  2.69s/it, loss=5.59, loss_1=0.000116, loss_2=0.000589, loss_3=5.59, lr=5e-5]Steps:  19%|‚ñà‚ñâ        | 19/100 [01:37<03:37,  2.69s/it, loss=5.59, loss_1=0.000247, loss_2=0.000524, loss_3=5.59, lr=5e-5]Steps:  20%|‚ñà‚ñà        | 20/100 [01:40<03:29,  2.62s/it, loss=5.59, loss_1=0.000247, loss_2=0.000524, loss_3=5.59, lr=5e-5]Steps:  20%|‚ñà‚ñà        | 20/100 [01:40<03:29,  2.62s/it, loss=5.59, loss_1=0.00119, loss_2=0.0012, loss_3=5.59, lr=5e-5]   Steps:  21%|‚ñà‚ñà        | 21/100 [01:42<03:18,  2.52s/it, loss=5.59, loss_1=0.00119, loss_2=0.0012, loss_3=5.59, lr=5e-5]Steps:  21%|‚ñà‚ñà        | 21/100 [01:42<03:18,  2.52s/it, loss=5.59, loss_1=4e-5, loss_2=8.95e-5, loss_3=5.59, lr=5e-5]  Steps:  22%|‚ñà‚ñà‚ñè       | 22/100 [01:44<03:16,  2.52s/it, loss=5.59, loss_1=4e-5, loss_2=8.95e-5, loss_3=5.59, lr=5e-5]Steps:  22%|‚ñà‚ñà‚ñè       | 22/100 [01:44<03:16,  2.52s/it, loss=5.59, loss_1=0.000994, loss_2=0.00102, loss_3=5.59, lr=5e-5]Steps:  23%|‚ñà‚ñà‚ñé       | 23/100 [01:47<03:09,  2.46s/it, loss=5.59, loss_1=0.000994, loss_2=0.00102, loss_3=5.59, lr=5e-5]Steps:  23%|‚ñà‚ñà‚ñé       | 23/100 [01:47<03:09,  2.46s/it, loss=5.59, loss_1=0.00022, loss_2=0.000478, loss_3=5.59, lr=5e-5]Steps:  24%|‚ñà‚ñà‚ñç       | 24/100 [01:49<03:06,  2.46s/it, loss=5.59, loss_1=0.00022, loss_2=0.000478, loss_3=5.59, lr=5e-5]Steps:  24%|‚ñà‚ñà‚ñç       | 24/100 [01:49<03:06,  2.46s/it, loss=5.59, loss_1=0.00263, loss_2=0.00378, loss_3=5.59, lr=5e-5] Steps:  25%|‚ñà‚ñà‚ñå       | 25/100 [01:52<03:01,  2.42s/it, loss=5.59, loss_1=0.00263, loss_2=0.00378, loss_3=5.59, lr=5e-5]Steps:  25%|‚ñà‚ñà‚ñå       | 25/100 [01:52<03:01,  2.42s/it, loss=5.59, loss_1=0.000381, loss_2=0.000871, loss_3=5.59, lr=5e-5]Steps:  26%|‚ñà‚ñà‚ñå       | 26/100 [01:54<02:59,  2.43s/it, loss=5.59, loss_1=0.000381, loss_2=0.000871, loss_3=5.59, lr=5e-5]Steps:  26%|‚ñà‚ñà‚ñå       | 26/100 [01:54<02:59,  2.43s/it, loss=5.59, loss_1=0.000262, loss_2=0.000577, loss_3=5.59, lr=5e-5]Steps:  27%|‚ñà‚ñà‚ñã       | 27/100 [01:56<02:55,  2.40s/it, loss=5.59, loss_1=0.000262, loss_2=0.000577, loss_3=5.59, lr=5e-5]Steps:  27%|‚ñà‚ñà‚ñã       | 27/100 [01:56<02:55,  2.40s/it, loss=5.59, loss_1=0.00245, loss_2=0.0024, loss_3=5.59, lr=5e-5]   Steps:  28%|‚ñà‚ñà‚ñä       | 28/100 [01:59<02:53,  2.40s/it, loss=5.59, loss_1=0.00245, loss_2=0.0024, loss_3=5.59, lr=5e-5]Steps:  28%|‚ñà‚ñà‚ñä       | 28/100 [01:59<02:53,  2.40s/it, loss=5.59, loss_1=0.00232, loss_2=0.00265, loss_3=5.58, lr=5e-5]Steps:  29%|‚ñà‚ñà‚ñâ       | 29/100 [02:01<02:50,  2.40s/it, loss=5.59, loss_1=0.00232, loss_2=0.00265, loss_3=5.58, lr=5e-5]Steps:  29%|‚ñà‚ñà‚ñâ       | 29/100 [02:01<02:50,  2.40s/it, loss=5.59, loss_1=0.000547, loss_2=0.000768, loss_3=5.58, lr=5e-5]Steps:  30%|‚ñà‚ñà‚ñà       | 30/100 [02:04<02:49,  2.42s/it, loss=5.59, loss_1=0.000547, loss_2=0.000768, loss_3=5.58, lr=5e-5]Steps:  30%|‚ñà‚ñà‚ñà       | 30/100 [02:04<02:49,  2.42s/it, loss=5.58, loss_1=2.35e-5, loss_2=2.17e-5, loss_3=5.58, lr=5e-5]  Steps:  31%|‚ñà‚ñà‚ñà       | 31/100 [02:06<02:45,  2.39s/it, loss=5.58, loss_1=2.35e-5, loss_2=2.17e-5, loss_3=5.58, lr=5e-5]Steps:  31%|‚ñà‚ñà‚ñà       | 31/100 [02:06<02:45,  2.39s/it, loss=5.59, loss_1=0.000602, loss_2=0.00133, loss_3=5.58, lr=5e-5]Steps:  32%|‚ñà‚ñà‚ñà‚ñè      | 32/100 [02:08<02:44,  2.41s/it, loss=5.59, loss_1=0.000602, loss_2=0.00133, loss_3=5.58, lr=5e-5]Steps:  32%|‚ñà‚ñà‚ñà‚ñè      | 32/100 [02:08<02:44,  2.41s/it, loss=5.59, loss_1=0.00162, loss_2=0.0042, loss_3=5.58, lr=5e-5]  Steps:  33%|‚ñà‚ñà‚ñà‚ñé      | 33/100 [02:11<02:39,  2.39s/it, loss=5.59, loss_1=0.00162, loss_2=0.0042, loss_3=5.58, lr=5e-5]Steps:  33%|‚ñà‚ñà‚ñà‚ñé      | 33/100 [02:11<02:39,  2.39s/it, loss=5.58, loss_1=0.00011, loss_2=8.34e-5, loss_3=5.58, lr=5e-5]Steps:  34%|‚ñà‚ñà‚ñà‚ñç      | 34/100 [02:13<02:38,  2.41s/it, loss=5.58, loss_1=0.00011, loss_2=8.34e-5, loss_3=5.58, lr=5e-5]Steps:  34%|‚ñà‚ñà‚ñà‚ñç      | 34/100 [02:13<02:38,  2.41s/it, loss=5.59, loss_1=0.00178, loss_2=0.00211, loss_3=5.58, lr=5e-5]Steps:  35%|‚ñà‚ñà‚ñà‚ñå      | 35/100 [02:15<02:34,  2.37s/it, loss=5.59, loss_1=0.00178, loss_2=0.00211, loss_3=5.58, lr=5e-5]Steps:  35%|‚ñà‚ñà‚ñà‚ñå      | 35/100 [02:15<02:34,  2.37s/it, loss=5.58, loss_1=0.000166, loss_2=0.000278, loss_3=5.58, lr=5e-5]Steps:  36%|‚ñà‚ñà‚ñà‚ñå      | 36/100 [02:18<02:34,  2.41s/it, loss=5.58, loss_1=0.000166, loss_2=0.000278, loss_3=5.58, lr=5e-5]Steps:  36%|‚ñà‚ñà‚ñà‚ñå      | 36/100 [02:18<02:34,  2.41s/it, loss=5.59, loss_1=0.00315, loss_2=0.00156, loss_3=5.58, lr=5e-5]  Steps:  37%|‚ñà‚ñà‚ñà‚ñã      | 37/100 [02:20<02:30,  2.39s/it, loss=5.59, loss_1=0.00315, loss_2=0.00156, loss_3=5.58, lr=5e-5]Steps:  37%|‚ñà‚ñà‚ñà‚ñã      | 37/100 [02:20<02:30,  2.39s/it, loss=5.58, loss_1=0.000101, loss_2=0.000128, loss_3=5.58, lr=5e-5]Steps:  38%|‚ñà‚ñà‚ñà‚ñä      | 38/100 [02:23<02:29,  2.41s/it, loss=5.58, loss_1=0.000101, loss_2=0.000128, loss_3=5.58, lr=5e-5]Steps:  38%|‚ñà‚ñà‚ñà‚ñä      | 38/100 [02:23<02:29,  2.41s/it, loss=5.58, loss_1=5.63e-5, loss_2=8.87e-5, loss_3=5.58, lr=5e-5]  Steps:  39%|‚ñà‚ñà‚ñà‚ñâ      | 39/100 [02:25<02:25,  2.38s/it, loss=5.58, loss_1=5.63e-5, loss_2=8.87e-5, loss_3=5.58, lr=5e-5]Steps:  39%|‚ñà‚ñà‚ñà‚ñâ      | 39/100 [02:25<02:25,  2.38s/it, loss=5.58, loss_1=0.00156, loss_2=0.00299, loss_3=5.58, lr=5e-5]Steps:  40%|‚ñà‚ñà‚ñà‚ñà      | 40/100 [02:28<02:24,  2.41s/it, loss=5.58, loss_1=0.00156, loss_2=0.00299, loss_3=5.58, lr=5e-5]Steps:  40%|‚ñà‚ñà‚ñà‚ñà      | 40/100 [02:28<02:24,  2.41s/it, loss=5.58, loss_1=0.00244, loss_2=0.00233, loss_3=5.58, lr=5e-5]Steps:  41%|‚ñà‚ñà‚ñà‚ñà      | 41/100 [02:30<02:20,  2.38s/it, loss=5.58, loss_1=0.00244, loss_2=0.00233, loss_3=5.58, lr=5e-5]Steps:  41%|‚ñà‚ñà‚ñà‚ñà      | 41/100 [02:30<02:20,  2.38s/it, loss=5.58, loss_1=0.00136, loss_2=0.00251, loss_3=5.58, lr=5e-5]Steps:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/100 [02:32<02:18,  2.39s/it, loss=5.58, loss_1=0.00136, loss_2=0.00251, loss_3=5.58, lr=5e-5]Steps:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/100 [02:32<02:18,  2.39s/it, loss=5.58, loss_1=0.000177, loss_2=0.000898, loss_3=5.58, lr=5e-5]Steps:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 43/100 [02:35<02:16,  2.39s/it, loss=5.58, loss_1=0.000177, loss_2=0.000898, loss_3=5.58, lr=5e-5]Steps:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 43/100 [02:35<02:16,  2.39s/it, loss=5.58, loss_1=0.00141, loss_2=0.00137, loss_3=5.58, lr=5e-5]  Steps:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 44/100 [02:37<02:15,  2.41s/it, loss=5.58, loss_1=0.00141, loss_2=0.00137, loss_3=5.58, lr=5e-5]Steps:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 44/100 [02:37<02:15,  2.41s/it, loss=5.58, loss_1=0.00024, loss_2=0.00112, loss_3=5.58, lr=5e-5]Steps:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 45/100 [02:40<02:11,  2.39s/it, loss=5.58, loss_1=0.00024, loss_2=0.00112, loss_3=5.58, lr=5e-5]Steps:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 45/100 [02:40<02:11,  2.39s/it, loss=5.58, loss_1=0.000616, loss_2=0.00129, loss_3=5.58, lr=5e-5]Steps:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/100 [02:42<02:10,  2.41s/it, loss=5.58, loss_1=0.000616, loss_2=0.00129, loss_3=5.58, lr=5e-5]Steps:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/100 [02:42<02:10,  2.41s/it, loss=5.58, loss_1=0.000206, loss_2=0.000263, loss_3=5.57, lr=5e-5]Steps:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 47/100 [02:44<02:06,  2.38s/it, loss=5.58, loss_1=0.000206, loss_2=0.000263, loss_3=5.57, lr=5e-5]Steps:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 47/100 [02:44<02:06,  2.38s/it, loss=5.58, loss_1=0.00134, loss_2=0.0027, loss_3=5.57, lr=5e-5]   Steps:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/100 [02:47<02:05,  2.41s/it, loss=5.58, loss_1=0.00134, loss_2=0.0027, loss_3=5.57, lr=5e-5]Steps:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/100 [02:47<02:05,  2.41s/it, loss=5.57, loss_1=5.4e-5, loss_2=7.98e-5, loss_3=5.57, lr=5e-5]Steps:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 49/100 [02:49<02:00,  2.37s/it, loss=5.57, loss_1=5.4e-5, loss_2=7.98e-5, loss_3=5.57, lr=5e-5]Steps:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 49/100 [02:49<02:00,  2.37s/it, loss=5.57, loss_1=0.000106, loss_2=0.000223, loss_3=5.57, lr=5e-5]Steps:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 50/100 [02:52<02:00,  2.41s/it, loss=5.57, loss_1=0.000106, loss_2=0.000223, loss_3=5.57, lr=5e-5]Steps:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 50/100 [02:52<02:00,  2.41s/it, loss=5.57, loss_1=0.000525, loss_2=0.000742, loss_3=5.57, lr=5e-5]Steps:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 51/100 [02:54<01:56,  2.39s/it, loss=5.57, loss_1=0.000525, loss_2=0.000742, loss_3=5.57, lr=5e-5]Steps:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 51/100 [02:54<01:56,  2.39s/it, loss=5.57, loss_1=1.77e-5, loss_2=3.55e-5, loss_3=5.57, lr=5e-5]  Steps:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/100 [02:56<01:55,  2.41s/it, loss=5.57, loss_1=1.77e-5, loss_2=3.55e-5, loss_3=5.57, lr=5e-5]Steps:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/100 [02:56<01:55,  2.41s/it, loss=5.58, loss_1=0.00251, loss_2=0.00394, loss_3=5.57, lr=5e-5]Steps:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 53/100 [02:59<01:52,  2.38s/it, loss=5.58, loss_1=0.00251, loss_2=0.00394, loss_3=5.57, lr=5e-5]Steps:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 53/100 [02:59<01:52,  2.38s/it, loss=5.58, loss_1=0.00314, loss_2=0.0022, loss_3=5.57, lr=5e-5] Steps:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 54/100 [03:01<01:50,  2.41s/it, loss=5.58, loss_1=0.00314, loss_2=0.0022, loss_3=5.57, lr=5e-5]Steps:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 54/100 [03:01<01:50,  2.41s/it, loss=5.58, loss_1=0.00185, loss_2=0.0028, loss_3=5.57, lr=5e-5]Steps:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 55/100 [03:03<01:47,  2.38s/it, loss=5.58, loss_1=0.00185, loss_2=0.0028, loss_3=5.57, lr=5e-5]Steps:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 55/100 [03:03<01:47,  2.38s/it, loss=5.57, loss_1=0.00125, loss_2=0.00119, loss_3=5.57, lr=5e-5]Steps:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 56/100 [03:06<01:45,  2.39s/it, loss=5.57, loss_1=0.00125, loss_2=0.00119, loss_3=5.57, lr=5e-5]Steps:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 56/100 [03:06<01:45,  2.39s/it, loss=5.57, loss_1=0.00217, loss_2=0.00317, loss_3=5.57, lr=5e-5]Steps:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 57/100 [03:08<01:42,  2.39s/it, loss=5.57, loss_1=0.00217, loss_2=0.00317, loss_3=5.57, lr=5e-5]Steps:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 57/100 [03:08<01:42,  2.39s/it, loss=5.57, loss_1=0.00249, loss_2=0.00238, loss_3=5.57, lr=5e-5]Steps:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 58/100 [03:11<01:41,  2.41s/it, loss=5.57, loss_1=0.00249, loss_2=0.00238, loss_3=5.57, lr=5e-5]Steps:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 58/100 [03:11<01:41,  2.41s/it, loss=5.57, loss_1=0.00246, loss_2=0.00344, loss_3=5.57, lr=5e-5]Steps:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 59/100 [03:13<01:37,  2.39s/it, loss=5.57, loss_1=0.00246, loss_2=0.00344, loss_3=5.57, lr=5e-5]Steps:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 59/100 [03:13<01:37,  2.39s/it, loss=5.57, loss_1=0.00251, loss_2=0.00373, loss_3=5.57, lr=5e-5]Steps:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 60/100 [03:15<01:36,  2.41s/it, loss=5.57, loss_1=0.00251, loss_2=0.00373, loss_3=5.57, lr=5e-5]Steps:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 60/100 [03:15<01:36,  2.41s/it, loss=5.57, loss_1=0.00213, loss_2=0.00238, loss_3=5.57, lr=5e-5]Steps:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 61/100 [03:18<01:32,  2.38s/it, loss=5.57, loss_1=0.00213, loss_2=0.00238, loss_3=5.57, lr=5e-5]Steps:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 61/100 [03:18<01:32,  2.38s/it, loss=5.57, loss_1=0.000855, loss_2=0.000942, loss_3=5.57, lr=5e-5]Steps:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/100 [03:20<01:31,  2.41s/it, loss=5.57, loss_1=0.000855, loss_2=0.000942, loss_3=5.57, lr=5e-5]Steps:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/100 [03:20<01:31,  2.41s/it, loss=5.57, loss_1=0.000753, loss_2=0.00174, loss_3=5.57, lr=5e-5] Steps:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 63/100 [03:23<01:27,  2.37s/it, loss=5.57, loss_1=0.000753, loss_2=0.00174, loss_3=5.57, lr=5e-5]Steps:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 63/100 [03:23<01:27,  2.37s/it, loss=5.57, loss_1=0.00185, loss_2=0.00319, loss_3=5.57, lr=5e-5] Steps:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 64/100 [03:25<01:26,  2.41s/it, loss=5.57, loss_1=0.00185, loss_2=0.00319, loss_3=5.57, lr=5e-5]Steps:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 64/100 [03:25<01:26,  2.41s/it, loss=5.57, loss_1=0.000213, loss_2=0.000214, loss_3=5.56, lr=5e-5]Steps:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 65/100 [03:27<01:23,  2.39s/it, loss=5.57, loss_1=0.000213, loss_2=0.000214, loss_3=5.56, lr=5e-5]Steps:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 65/100 [03:27<01:23,  2.39s/it, loss=5.56, loss_1=3.94e-5, loss_2=3.96e-5, loss_3=5.56, lr=5e-5]  Steps:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/100 [03:30<01:21,  2.41s/it, loss=5.56, loss_1=3.94e-5, loss_2=3.96e-5, loss_3=5.56, lr=5e-5]Steps:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/100 [03:30<01:21,  2.41s/it, loss=5.56, loss_1=8.63e-5, loss_2=0.000146, loss_3=5.56, lr=5e-5]Steps:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 67/100 [03:32<01:18,  2.38s/it, loss=5.56, loss_1=8.63e-5, loss_2=0.000146, loss_3=5.56, lr=5e-5]Steps:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 67/100 [03:32<01:18,  2.38s/it, loss=5.56, loss_1=7.12e-5, loss_2=0.000161, loss_3=5.56, lr=5e-5]Steps:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 68/100 [03:35<01:17,  2.41s/it, loss=5.56, loss_1=7.12e-5, loss_2=0.000161, loss_3=5.56, lr=5e-5]Steps:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 68/100 [03:35<01:17,  2.41s/it, loss=5.56, loss_1=5.35e-5, loss_2=7.09e-5, loss_3=5.56, lr=5e-5] Steps:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 69/100 [03:37<01:13,  2.38s/it, loss=5.56, loss_1=5.35e-5, loss_2=7.09e-5, loss_3=5.56, lr=5e-5]Steps:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 69/100 [03:37<01:13,  2.38s/it, loss=5.56, loss_1=0.000249, loss_2=0.00043, loss_3=5.56, lr=5e-5]Steps:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 70/100 [03:39<01:11,  2.39s/it, loss=5.56, loss_1=0.000249, loss_2=0.00043, loss_3=5.56, lr=5e-5]Steps:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 70/100 [03:39<01:11,  2.39s/it, loss=5.56, loss_1=4.02e-5, loss_2=5.64e-5, loss_3=5.56, lr=5e-5] Steps:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 71/100 [03:42<01:09,  2.39s/it, loss=5.56, loss_1=4.02e-5, loss_2=5.64e-5, loss_3=5.56, lr=5e-5]Steps:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 71/100 [03:42<01:09,  2.39s/it, loss=5.56, loss_1=0.000889, loss_2=0.00211, loss_3=5.56, lr=5e-5]Steps:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/100 [03:44<01:07,  2.41s/it, loss=5.56, loss_1=0.000889, loss_2=0.00211, loss_3=5.56, lr=5e-5]Steps:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/100 [03:44<01:07,  2.41s/it, loss=5.57, loss_1=0.00196, loss_2=0.00273, loss_3=5.56, lr=5e-5] Steps:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 73/100 [03:47<01:04,  2.39s/it, loss=5.57, loss_1=0.00196, loss_2=0.00273, loss_3=5.56, lr=5e-5]Steps:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 73/100 [03:47<01:04,  2.39s/it, loss=5.56, loss_1=0.000131, loss_2=0.00017, loss_3=5.56, lr=5e-5]Steps:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 74/100 [03:49<01:02,  2.41s/it, loss=5.56, loss_1=0.000131, loss_2=0.00017, loss_3=5.56, lr=5e-5]Steps:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 74/100 [03:49<01:02,  2.41s/it, loss=5.56, loss_1=0.00039, loss_2=0.000487, loss_3=5.56, lr=5e-5]Steps:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 75/100 [03:51<00:59,  2.38s/it, loss=5.56, loss_1=0.00039, loss_2=0.000487, loss_3=5.56, lr=5e-5]Steps:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 75/100 [03:51<00:59,  2.38s/it, loss=5.56, loss_1=0.0016, loss_2=0.00139, loss_3=5.56, lr=5e-5]  Steps:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/100 [03:54<00:57,  2.41s/it, loss=5.56, loss_1=0.0016, loss_2=0.00139, loss_3=5.56, lr=5e-5]Steps:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/100 [03:54<00:57,  2.41s/it, loss=5.56, loss_1=0.00254, loss_2=0.00403, loss_3=5.56, lr=5e-5]Steps:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 77/100 [03:56<00:54,  2.37s/it, loss=5.56, loss_1=0.00254, loss_2=0.00403, loss_3=5.56, lr=5e-5]Steps:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 77/100 [03:56<00:54,  2.37s/it, loss=5.56, loss_1=0.00133, loss_2=0.00225, loss_3=5.56, lr=5e-5]06/11/2024 15:17:23 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: a sbu dog in the crt style.
{'image_encoder', 'feature_extractor'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][ALoaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of stabilityai/stable-diffusion-xl-base-1.0.
{'sigma_min', 'timestep_type', 'sigma_max'} was not found in config. Values will be initialized to default values.
Loaded scheduler as EulerDiscreteScheduler from `scheduler` subfolder of stabilityai/stable-diffusion-xl-base-1.0.
Loaded tokenizer_2 as CLIPTokenizer from `tokenizer_2` subfolder of stabilityai/stable-diffusion-xl-base-1.0.

Loading pipeline components...:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:00<00:00, 37.77it/s][ALoading pipeline components...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 52.61it/s]
{'solver_order', 'variance_type', 'dynamic_thresholding_ratio', 'thresholding', 'lambda_min_clipped', 'euler_at_final', 'solver_type', 'use_lu_lambdas', 'algorithm_type', 'lower_order_final'} was not found in config. Values will be initialized to default values.
Steps:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 78/100 [04:48<06:19, 17.24s/it, loss=5.56, loss_1=0.00133, loss_2=0.00225, loss_3=5.56, lr=5e-5]Steps:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 78/100 [04:48<06:19, 17.24s/it, loss=5.56, loss_1=0.000448, loss_2=0.0016, loss_3=5.56, lr=5e-5]Steps:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 79/100 [04:50<04:28, 12.77s/it, loss=5.56, loss_1=0.000448, loss_2=0.0016, loss_3=5.56, lr=5e-5]Steps:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 79/100 [04:50<04:28, 12.77s/it, loss=5.56, loss_1=0.00239, loss_2=0.00231, loss_3=5.56, lr=5e-5]Steps:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 80/100 [04:53<03:13,  9.68s/it, loss=5.56, loss_1=0.00239, loss_2=0.00231, loss_3=5.56, lr=5e-5]Steps:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 80/100 [04:53<03:13,  9.68s/it, loss=5.56, loss_1=0.00134, loss_2=0.0028, loss_3=5.56, lr=5e-5] Steps:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 81/100 [04:55<02:21,  7.47s/it, loss=5.56, loss_1=0.00134, loss_2=0.0028, loss_3=5.56, lr=5e-5]Steps:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 81/100 [04:55<02:21,  7.47s/it, loss=5.56, loss_1=7.29e-5, loss_2=9.26e-5, loss_3=5.56, lr=5e-5]Steps:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 82/100 [04:58<01:47,  5.97s/it, loss=5.56, loss_1=7.29e-5, loss_2=9.26e-5, loss_3=5.56, lr=5e-5]Steps:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 82/100 [04:58<01:47,  5.97s/it, loss=5.56, loss_1=0.000508, loss_2=0.000629, loss_3=5.55, lr=5e-5]Steps:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 83/100 [05:00<01:23,  4.92s/it, loss=5.56, loss_1=0.000508, loss_2=0.000629, loss_3=5.55, lr=5e-5]Steps:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 83/100 [05:00<01:23,  4.92s/it, loss=5.56, loss_1=0.000881, loss_2=0.00181, loss_3=5.55, lr=5e-5] Steps:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 84/100 [05:02<01:06,  4.13s/it, loss=5.56, loss_1=0.000881, loss_2=0.00181, loss_3=5.55, lr=5e-5]Steps:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 84/100 [05:02<01:06,  4.13s/it, loss=5.56, loss_1=0.00103, loss_2=0.00132, loss_3=5.55, lr=5e-5] Steps:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 85/100 [05:05<00:54,  3.64s/it, loss=5.56, loss_1=0.00103, loss_2=0.00132, loss_3=5.55, lr=5e-5]Steps:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 85/100 [05:05<00:54,  3.64s/it, loss=5.56, loss_1=0.00202, loss_2=0.00425, loss_3=5.55, lr=5e-5]Steps:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/100 [05:07<00:45,  3.25s/it, loss=5.56, loss_1=0.00202, loss_2=0.00425, loss_3=5.55, lr=5e-5]Steps:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/100 [05:07<00:45,  3.25s/it, loss=5.56, loss_1=0.00222, loss_2=0.00313, loss_3=5.55, lr=5e-5]Steps:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 87/100 [05:10<00:39,  3.01s/it, loss=5.56, loss_1=0.00222, loss_2=0.00313, loss_3=5.55, lr=5e-5]Steps:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 87/100 [05:10<00:39,  3.01s/it, loss=5.56, loss_1=0.00132, loss_2=0.00259, loss_3=5.55, lr=5e-5]Steps:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 88/100 [05:12<00:33,  2.81s/it, loss=5.56, loss_1=0.00132, loss_2=0.00259, loss_3=5.55, lr=5e-5]Steps:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 88/100 [05:12<00:33,  2.81s/it, loss=5.56, loss_1=0.0019, loss_2=0.00245, loss_3=5.55, lr=5e-5] Steps:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 89/100 [05:14<00:29,  2.70s/it, loss=5.56, loss_1=0.0019, loss_2=0.00245, loss_3=5.55, lr=5e-5]Steps:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 89/100 [05:14<00:29,  2.70s/it, loss=5.56, loss_1=0.0025, loss_2=0.00159, loss_3=5.55, lr=5e-5]Steps:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 90/100 [05:17<00:25,  2.59s/it, loss=5.56, loss_1=0.0025, loss_2=0.00159, loss_3=5.55, lr=5e-5]Steps:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 90/100 [05:17<00:25,  2.59s/it, loss=5.55, loss_1=0.000323, loss_2=0.000905, loss_3=5.55, lr=5e-5]Steps:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 91/100 [05:19<00:22,  2.54s/it, loss=5.55, loss_1=0.000323, loss_2=0.000905, loss_3=5.55, lr=5e-5]Steps:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 91/100 [05:19<00:22,  2.54s/it, loss=5.55, loss_1=0.000118, loss_2=0.000285, loss_3=5.55, lr=5e-5]Steps:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 92/100 [05:22<00:19,  2.49s/it, loss=5.55, loss_1=0.000118, loss_2=0.000285, loss_3=5.55, lr=5e-5]Steps:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 92/100 [05:22<00:19,  2.49s/it, loss=5.56, loss_1=0.00191, loss_2=0.00434, loss_3=5.55, lr=5e-5]  Steps:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 93/100 [05:24<00:17,  2.48s/it, loss=5.56, loss_1=0.00191, loss_2=0.00434, loss_3=5.55, lr=5e-5]Steps:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 93/100 [05:24<00:17,  2.48s/it, loss=5.55, loss_1=7.6e-5, loss_2=6.75e-5, loss_3=5.55, lr=5e-5] Steps:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 94/100 [05:26<00:14,  2.43s/it, loss=5.55, loss_1=7.6e-5, loss_2=6.75e-5, loss_3=5.55, lr=5e-5]Steps:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 94/100 [05:26<00:14,  2.43s/it, loss=5.55, loss_1=0.00227, loss_2=0.00335, loss_3=5.55, lr=5e-5]Steps:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 95/100 [05:29<00:12,  2.44s/it, loss=5.55, loss_1=0.00227, loss_2=0.00335, loss_3=5.55, lr=5e-5]Steps:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 95/100 [05:29<00:12,  2.44s/it, loss=5.55, loss_1=0.00162, loss_2=0.00272, loss_3=5.55, lr=5e-5]Steps:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/100 [05:31<00:09,  2.41s/it, loss=5.55, loss_1=0.00162, loss_2=0.00272, loss_3=5.55, lr=5e-5]Steps:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/100 [05:31<00:09,  2.41s/it, loss=5.55, loss_1=0.00175, loss_2=0.00143, loss_3=5.55, lr=5e-5]Steps:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 97/100 [05:34<00:07,  2.42s/it, loss=5.55, loss_1=0.00175, loss_2=0.00143, loss_3=5.55, lr=5e-5]Steps:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 97/100 [05:34<00:07,  2.42s/it, loss=5.55, loss_1=0.00182, loss_2=0.00231, loss_3=5.55, lr=5e-5]Steps:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 98/100 [05:36<00:04,  2.38s/it, loss=5.55, loss_1=0.00182, loss_2=0.00231, loss_3=5.55, lr=5e-5]Steps:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 98/100 [05:36<00:04,  2.38s/it, loss=5.55, loss_1=0.000603, loss_2=0.000878, loss_3=5.55, lr=5e-5]Steps:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 99/100 [05:38<00:02,  2.42s/it, loss=5.55, loss_1=0.000603, loss_2=0.000878, loss_3=5.55, lr=5e-5]Steps:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 99/100 [05:38<00:02,  2.42s/it, loss=5.55, loss_1=0.00203, loss_2=0.00257, loss_3=5.55, lr=5e-5]  Steps: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [05:41<00:00,  2.39s/it, loss=5.55, loss_1=0.00203, loss_2=0.00257, loss_3=5.55, lr=5e-5]Steps: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [05:41<00:00,  2.39s/it, loss=5.55, loss_1=0.000628, loss_2=0.00177, loss_3=5.54, lr=5e-5]Model weights saved in ./models/ziplora_style3_rank32_dog6_lambda_0_01_2024-06-11_15-12-37/pytorch_lora_weights.safetensors
{'image_encoder', 'feature_extractor'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][ALoaded text_encoder_2 as CLIPTextModelWithProjection from `text_encoder_2` subfolder of stabilityai/stable-diffusion-xl-base-1.0.

Loading pipeline components...:  14%|‚ñà‚ñç        | 1/7 [00:02<00:15,  2.60s/it][A{'attention_type', 'dropout', 'reverse_transformer_layers_per_block'} was not found in config. Values will be initialized to default values.
Loaded unet as UNet2DConditionModel from `unet` subfolder of stabilityai/stable-diffusion-xl-base-1.0.

Loading pipeline components...:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:09<00:26,  5.38s/it][ALoaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of stabilityai/stable-diffusion-xl-base-1.0.
{'sigma_min', 'timestep_type', 'sigma_max'} was not found in config. Values will be initialized to default values.
Loaded scheduler as EulerDiscreteScheduler from `scheduler` subfolder of stabilityai/stable-diffusion-xl-base-1.0.
Loaded tokenizer_2 as CLIPTokenizer from `tokenizer_2` subfolder of stabilityai/stable-diffusion-xl-base-1.0.

Loading pipeline components...:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:10<00:03,  1.56s/it][ALoaded text_encoder as CLIPTextModel from `text_encoder` subfolder of stabilityai/stable-diffusion-xl-base-1.0.

Loading pipeline components...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:10<00:00,  1.04s/it][ALoading pipeline components...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:10<00:00,  1.51s/it]
{'solver_order', 'variance_type', 'dynamic_thresholding_ratio', 'thresholding', 'lambda_min_clipped', 'euler_at_final', 'solver_type', 'use_lu_lambdas', 'algorithm_type', 'lower_order_final'} was not found in config. Values will be initialized to default values.

  0%|          | 0/25 [00:00<?, ?it/s][A
  4%|‚ñç         | 1/25 [00:00<00:04,  4.89it/s][A
  8%|‚ñä         | 2/25 [00:00<00:03,  6.98it/s][A
 12%|‚ñà‚ñè        | 3/25 [00:00<00:02,  7.57it/s][A
 16%|‚ñà‚ñå        | 4/25 [00:00<00:02,  7.66it/s][A
 20%|‚ñà‚ñà        | 5/25 [00:00<00:02,  7.70it/s][A
 24%|‚ñà‚ñà‚ñç       | 6/25 [00:00<00:02,  7.73it/s][A
 28%|‚ñà‚ñà‚ñä       | 7/25 [00:00<00:02,  7.74it/s][A
 32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:01<00:02,  7.75it/s][A
 36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:01<00:02,  7.76it/s][A
 40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:01<00:01,  7.77it/s][A
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:01<00:01,  7.77it/s][A
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:01<00:01,  7.77it/s][A
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:01<00:01,  7.78it/s][A
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:01<00:01,  7.78it/s][A
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:01<00:01,  7.78it/s][A
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:02<00:01,  7.78it/s][A
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:02<00:01,  7.78it/s][A
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:02<00:00,  7.78it/s][A
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:02<00:00,  7.78it/s][A
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:02<00:00,  7.79it/s][A
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:02<00:00,  7.79it/s][A
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:02<00:00,  7.79it/s][A
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:02<00:00,  7.79it/s][A
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:03<00:00,  7.79it/s][A
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:03<00:00,  7.80it/s][A100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:03<00:00,  7.69it/s]

  0%|          | 0/25 [00:00<?, ?it/s][A
  4%|‚ñç         | 1/25 [00:00<00:03,  7.72it/s][A
  8%|‚ñä         | 2/25 [00:00<00:02,  8.87it/s][A
 12%|‚ñà‚ñè        | 3/25 [00:00<00:02,  8.67it/s][A
 16%|‚ñà‚ñå        | 4/25 [00:00<00:02,  8.30it/s][A
 20%|‚ñà‚ñà        | 5/25 [00:00<00:02,  8.11it/s][A
 24%|‚ñà‚ñà‚ñç       | 6/25 [00:00<00:02,  8.00it/s][A
 28%|‚ñà‚ñà‚ñä       | 7/25 [00:00<00:02,  7.93it/s][A
 32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:00<00:02,  7.89it/s][A
 36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:01<00:02,  7.86it/s][A
 40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:01<00:01,  7.84it/s][A
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:01<00:01,  7.83it/s][A
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:01<00:01,  7.82it/s][A
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:01<00:01,  7.81it/s][A
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:01<00:01,  7.80it/s][A
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:01<00:01,  7.81it/s][A
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:02<00:01,  7.81it/s][A
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:02<00:01,  7.80it/s][A
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:02<00:00,  7.80it/s][A
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:02<00:00,  7.80it/s][A
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:02<00:00,  7.80it/s][A
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:02<00:00,  7.80it/s][A
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:02<00:00,  7.80it/s][A
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:02<00:00,  7.80it/s][A
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:03<00:00,  7.80it/s][A
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:03<00:00,  7.80it/s][A100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:03<00:00,  7.88it/s]

  0%|          | 0/25 [00:00<?, ?it/s][A
  4%|‚ñç         | 1/25 [00:00<00:03,  7.71it/s][A
  8%|‚ñä         | 2/25 [00:00<00:02,  8.87it/s][A
 12%|‚ñà‚ñè        | 3/25 [00:00<00:02,  8.66it/s][A
 16%|‚ñà‚ñå        | 4/25 [00:00<00:02,  8.28it/s][A
 20%|‚ñà‚ñà        | 5/25 [00:00<00:02,  8.09it/s][A
 24%|‚ñà‚ñà‚ñç       | 6/25 [00:00<00:02,  7.98it/s][A
 28%|‚ñà‚ñà‚ñä       | 7/25 [00:00<00:02,  7.92it/s][A
 32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:00<00:02,  7.87it/s][A
 36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:01<00:02,  7.84it/s][A
 40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:01<00:01,  7.83it/s][A
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:01<00:01,  7.81it/s][A
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:01<00:01,  7.80it/s][A
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:01<00:01,  7.80it/s][A
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:01<00:01,  7.80it/s][A
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:01<00:01,  7.79it/s][A
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:02<00:01,  7.79it/s][A
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:02<00:01,  7.79it/s][A
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:02<00:00,  7.79it/s][A
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:02<00:00,  7.78it/s][A
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:02<00:00,  7.79it/s][A
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:02<00:00,  7.79it/s][A
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:02<00:00,  7.78it/s][A
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:02<00:00,  7.78it/s][A
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:03<00:00,  7.78it/s][A
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:03<00:00,  7.78it/s][A100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:03<00:00,  7.87it/s]

  0%|          | 0/25 [00:00<?, ?it/s][A
  4%|‚ñç         | 1/25 [00:00<00:03,  7.71it/s][A
  8%|‚ñä         | 2/25 [00:00<00:02,  8.89it/s][A
 12%|‚ñà‚ñè        | 3/25 [00:00<00:02,  8.65it/s][A
 16%|‚ñà‚ñå        | 4/25 [00:00<00:02,  8.28it/s][A
 20%|‚ñà‚ñà        | 5/25 [00:00<00:02,  8.09it/s][A
 24%|‚ñà‚ñà‚ñç       | 6/25 [00:00<00:02,  7.98it/s][A
 28%|‚ñà‚ñà‚ñä       | 7/25 [00:00<00:02,  7.91it/s][A
 32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:00<00:02,  7.88it/s][A
 36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:01<00:02,  7.84it/s][A
 40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:01<00:01,  7.82it/s][A
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:01<00:01,  7.81it/s][A
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:01<00:01,  7.80it/s][A
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:01<00:01,  7.79it/s][A
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:01<00:01,  7.79it/s][A
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:01<00:01,  7.79it/s][A
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:02<00:01,  7.79it/s][A
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:02<00:01,  7.78it/s][A
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:02<00:00,  7.78it/s][A
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:02<00:00,  7.78it/s][A
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:02<00:00,  7.78it/s][A
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:02<00:00,  7.78it/s][A
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:02<00:00,  7.78it/s][A
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:02<00:00,  7.78it/s][A
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:03<00:00,  7.78it/s][A
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:03<00:00,  7.78it/s][A100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:03<00:00,  7.87it/s]
wandb: - 13.242 MB of 13.242 MB uploadedwandb: \ 13.242 MB of 13.257 MB uploadedwandb: | 13.257 MB of 13.257 MB uploadedwandb: / 13.257 MB of 13.257 MB uploadedwandb: - 13.257 MB of 13.257 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:   loss ‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb: loss_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñÇ‚ñÖ‚ñà‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÇ‚ñÑ‚ñÜ‚ñÇ‚ñÉ‚ñÑ‚ñá‚ñÖ‚ñÜ‚ñÖ‚ñÇ
wandb: loss_2 ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÖ‚ñÉ‚ñÑ‚ñÉ‚ñÜ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÇ‚ñÖ‚ñÖ‚ñÇ‚ñÉ‚ñÖ‚ñÑ‚ñà‚ñÜ‚ñÖ‚ñÑ
wandb: loss_3 ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:     lr ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   loss 5.54722
wandb: loss_1 0.00063
wandb: loss_2 0.00177
wandb: loss_3 5.54482
wandb:     lr 5e-05
wandb: 
wandb: üöÄ View run valiant-valley-14 at: https://wandb.ai/salbowic-org/dreambooth-ziplora-sd-xl/runs/nz37yu6d
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/salbowic-org/dreambooth-ziplora-sd-xl
wandb: Synced 6 W&B file(s), 12 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240611_151323-nz37yu6d/logs
/net/tscratch/people/plgas2000/.conda/envs/myenv2/lib/python3.9/site-packages/wandb/sdk/wandb_run.py:2265: UserWarning: Run (nz37yu6d) is finished. The call to `_console_raw_callback` will be ignored. Please make sure that you are using an active run.
  lambda data: self._console_raw_callback("stderr", data),
Steps: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [06:28<00:00,  3.88s/it, loss=5.55, loss_1=0.000628, loss_2=0.00177, loss_3=5.54, lr=5e-5]
