The following values were not passed to `accelerate launch` and had defaults used instead:
	`--num_processes` was set to a value of `1`
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
/net/tscratch/people/plgas2000/.conda/envs/myenv2/lib/python3.9/site-packages/diffusers/utils/outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
  torch.utils._pytree._register_pytree_node(
05/28/2024 03:30:07 - INFO - __main__ - Distributed environment: NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda

Mixed precision type: fp16

You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.
You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.
/net/tscratch/people/plgas2000/.conda/envs/myenv2/lib/python3.9/site-packages/diffusers/utils/outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
  torch.utils._pytree._register_pytree_node(
{'thresholding', 'clip_sample_range', 'variance_type', 'dynamic_thresholding_ratio'} was not found in config. Values will be initialized to default values.
{'dropout', 'reverse_transformer_layers_per_block', 'attention_type'} was not found in config. Values will be initialized to default values.
05/28/2024 03:30:35 - INFO - __main__ - Number of Trainable Parameters: 1.57 M
wandb: Currently logged in as: salbowic (salbowic-org). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.17.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in /net/tscratch/people/plgas2000/zzsn-project/wandb/run-20240528_033039-q1338fxq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swept-armadillo-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/salbowic-org/dreambooth-ziplora-sd-xl
wandb: üöÄ View run at https://wandb.ai/salbowic-org/dreambooth-ziplora-sd-xl/runs/q1338fxq
05/28/2024 03:30:42 - INFO - __main__ - ***** Running training *****
05/28/2024 03:30:42 - INFO - __main__ -   Num examples = 7
05/28/2024 03:30:42 - INFO - __main__ -   Num batches each epoch = 7
05/28/2024 03:30:42 - INFO - __main__ -   Num Epochs = 15
05/28/2024 03:30:42 - INFO - __main__ -   Instantaneous batch size per device = 1
05/28/2024 03:30:42 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 1
05/28/2024 03:30:42 - INFO - __main__ -   Gradient Accumulation steps = 1
05/28/2024 03:30:42 - INFO - __main__ -   Total optimization steps = 100
Steps:   0%|          | 0/100 [00:00<?, ?it/s]Steps:   1%|          | 1/100 [00:03<06:05,  3.69s/it]Steps:   1%|          | 1/100 [00:03<06:05,  3.69s/it, loss=5.6, loss_1=0.000106, loss_2=0.000176, loss_3=5.6, lr=5e-5]Steps:   2%|‚ñè         | 2/100 [00:06<04:43,  2.90s/it, loss=5.6, loss_1=0.000106, loss_2=0.000176, loss_3=5.6, lr=5e-5]Steps:   2%|‚ñè         | 2/100 [00:06<04:43,  2.90s/it, loss=5.6, loss_1=0.000187, loss_2=0.000619, loss_3=5.6, lr=5e-5]Steps:   3%|‚ñé         | 3/100 [00:08<04:11,  2.60s/it, loss=5.6, loss_1=0.000187, loss_2=0.000619, loss_3=5.6, lr=5e-5]Steps:   3%|‚ñé         | 3/100 [00:08<04:11,  2.60s/it, loss=5.6, loss_1=9.97e-5, loss_2=0.000121, loss_3=5.6, lr=5e-5] Steps:   4%|‚ñç         | 4/100 [00:10<03:59,  2.50s/it, loss=5.6, loss_1=9.97e-5, loss_2=0.000121, loss_3=5.6, lr=5e-5]Steps:   4%|‚ñç         | 4/100 [00:10<03:59,  2.50s/it, loss=5.6, loss_1=0.000224, loss_2=0.000715, loss_3=5.6, lr=5e-5]Steps:   5%|‚ñå         | 5/100 [00:12<03:48,  2.40s/it, loss=5.6, loss_1=0.000224, loss_2=0.000715, loss_3=5.6, lr=5e-5]Steps:   5%|‚ñå         | 5/100 [00:12<03:48,  2.40s/it, loss=5.6, loss_1=0.000199, loss_2=0.000181, loss_3=5.6, lr=5e-5]Steps:   6%|‚ñå         | 6/100 [00:15<03:44,  2.39s/it, loss=5.6, loss_1=0.000199, loss_2=0.000181, loss_3=5.6, lr=5e-5]Steps:   6%|‚ñå         | 6/100 [00:15<03:44,  2.39s/it, loss=5.6, loss_1=0.000979, loss_2=0.00266, loss_3=5.6, lr=5e-5] Steps:   7%|‚ñã         | 7/100 [00:17<03:36,  2.32s/it, loss=5.6, loss_1=0.000979, loss_2=0.00266, loss_3=5.6, lr=5e-5]Steps:   7%|‚ñã         | 7/100 [00:17<03:36,  2.32s/it, loss=5.6, loss_1=2.35e-5, loss_2=6.28e-5, loss_3=5.6, lr=5e-5] 05/28/2024 03:30:59 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: a sks dog in crt style.
{'image_encoder', 'feature_extractor'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][A{'timestep_type', 'sigma_min', 'sigma_max'} was not found in config. Values will be initialized to default values.
Loaded scheduler as EulerDiscreteScheduler from `scheduler` subfolder of stabilityai/stable-diffusion-xl-base-1.0.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of stabilityai/stable-diffusion-xl-base-1.0.
Loaded tokenizer_2 as CLIPTokenizer from `tokenizer_2` subfolder of stabilityai/stable-diffusion-xl-base-1.0.

Loading pipeline components...:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:00<00:00, 37.19it/s][ALoading pipeline components...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 51.84it/s]
{'solver_order', 'variance_type', 'dynamic_thresholding_ratio', 'lambda_min_clipped', 'algorithm_type', 'solver_type', 'lower_order_final', 'use_lu_lambdas', 'euler_at_final', 'thresholding'} was not found in config. Values will be initialized to default values.
Steps:   8%|‚ñä         | 8/100 [01:09<27:38, 18.03s/it, loss=5.6, loss_1=2.35e-5, loss_2=6.28e-5, loss_3=5.6, lr=5e-5]Steps:   8%|‚ñä         | 8/100 [01:09<27:38, 18.03s/it, loss=5.6, loss_1=0.00203, loss_2=0.00181, loss_3=5.6, lr=5e-5]Steps:   9%|‚ñâ         | 9/100 [01:11<19:54, 13.13s/it, loss=5.6, loss_1=0.00203, loss_2=0.00181, loss_3=5.6, lr=5e-5]Steps:   9%|‚ñâ         | 9/100 [01:11<19:54, 13.13s/it, loss=5.6, loss_1=0.000107, loss_2=0.000114, loss_3=5.6, lr=5e-5]Steps:  10%|‚ñà         | 10/100 [01:13<14:38,  9.77s/it, loss=5.6, loss_1=0.000107, loss_2=0.000114, loss_3=5.6, lr=5e-5]Steps:  10%|‚ñà         | 10/100 [01:13<14:38,  9.77s/it, loss=5.6, loss_1=0.000119, loss_2=0.00016, loss_3=5.59, lr=5e-5]Steps:  11%|‚ñà         | 11/100 [01:16<11:07,  7.50s/it, loss=5.6, loss_1=0.000119, loss_2=0.00016, loss_3=5.59, lr=5e-5]Steps:  11%|‚ñà         | 11/100 [01:16<11:07,  7.50s/it, loss=5.6, loss_1=0.000684, loss_2=0.00205, loss_3=5.59, lr=5e-5]Steps:  12%|‚ñà‚ñè        | 12/100 [01:18<08:39,  5.90s/it, loss=5.6, loss_1=0.000684, loss_2=0.00205, loss_3=5.59, lr=5e-5]Steps:  12%|‚ñà‚ñè        | 12/100 [01:18<08:39,  5.90s/it, loss=5.59, loss_1=1.38e-5, loss_2=6.86e-5, loss_3=5.59, lr=5e-5]Steps:  13%|‚ñà‚ñé        | 13/100 [01:20<06:59,  4.82s/it, loss=5.59, loss_1=1.38e-5, loss_2=6.86e-5, loss_3=5.59, lr=5e-5]Steps:  13%|‚ñà‚ñé        | 13/100 [01:20<06:59,  4.82s/it, loss=5.6, loss_1=0.00205, loss_2=0.00232, loss_3=5.59, lr=5e-5] Steps:  14%|‚ñà‚ñç        | 14/100 [01:22<05:46,  4.03s/it, loss=5.6, loss_1=0.00205, loss_2=0.00232, loss_3=5.59, lr=5e-5]Steps:  14%|‚ñà‚ñç        | 14/100 [01:22<05:46,  4.03s/it, loss=5.59, loss_1=0.00016, loss_2=0.000924, loss_3=5.59, lr=5e-5]Steps:  15%|‚ñà‚ñå        | 15/100 [01:25<05:00,  3.54s/it, loss=5.59, loss_1=0.00016, loss_2=0.000924, loss_3=5.59, lr=5e-5]Steps:  15%|‚ñà‚ñå        | 15/100 [01:25<05:00,  3.54s/it, loss=5.59, loss_1=0.000365, loss_2=0.000559, loss_3=5.59, lr=5e-5]Steps:  16%|‚ñà‚ñå        | 16/100 [01:27<04:27,  3.18s/it, loss=5.59, loss_1=0.000365, loss_2=0.000559, loss_3=5.59, lr=5e-5]Steps:  16%|‚ñà‚ñå        | 16/100 [01:27<04:27,  3.18s/it, loss=5.59, loss_1=6.78e-5, loss_2=9.95e-5, loss_3=5.59, lr=5e-5]  Steps:  17%|‚ñà‚ñã        | 17/100 [01:29<04:00,  2.90s/it, loss=5.59, loss_1=6.78e-5, loss_2=9.95e-5, loss_3=5.59, lr=5e-5]Steps:  17%|‚ñà‚ñã        | 17/100 [01:29<04:00,  2.90s/it, loss=5.59, loss_1=0.00106, loss_2=0.00217, loss_3=5.59, lr=5e-5]Steps:  18%|‚ñà‚ñä        | 18/100 [01:32<03:44,  2.74s/it, loss=5.59, loss_1=0.00106, loss_2=0.00217, loss_3=5.59, lr=5e-5]Steps:  18%|‚ñà‚ñä        | 18/100 [01:32<03:44,  2.74s/it, loss=5.59, loss_1=1.37e-5, loss_2=6.66e-5, loss_3=5.59, lr=5e-5]Steps:  19%|‚ñà‚ñâ        | 19/100 [01:34<03:29,  2.59s/it, loss=5.59, loss_1=1.37e-5, loss_2=6.66e-5, loss_3=5.59, lr=5e-5]Steps:  19%|‚ñà‚ñâ        | 19/100 [01:34<03:29,  2.59s/it, loss=5.59, loss_1=0.000136, loss_2=0.000483, loss_3=5.59, lr=5e-5]Steps:  20%|‚ñà‚ñà        | 20/100 [01:36<03:21,  2.52s/it, loss=5.59, loss_1=0.000136, loss_2=0.000483, loss_3=5.59, lr=5e-5]Steps:  20%|‚ñà‚ñà        | 20/100 [01:36<03:21,  2.52s/it, loss=5.59, loss_1=0.000847, loss_2=0.00225, loss_3=5.59, lr=5e-5] Steps:  21%|‚ñà‚ñà        | 21/100 [01:38<03:11,  2.43s/it, loss=5.59, loss_1=0.000847, loss_2=0.00225, loss_3=5.59, lr=5e-5]Steps:  21%|‚ñà‚ñà        | 21/100 [01:38<03:11,  2.43s/it, loss=5.59, loss_1=0.001, loss_2=0.0018, loss_3=5.59, lr=5e-5]    Steps:  22%|‚ñà‚ñà‚ñè       | 22/100 [01:41<03:08,  2.42s/it, loss=5.59, loss_1=0.001, loss_2=0.0018, loss_3=5.59, lr=5e-5]Steps:  22%|‚ñà‚ñà‚ñè       | 22/100 [01:41<03:08,  2.42s/it, loss=5.59, loss_1=0.00169, loss_2=0.00233, loss_3=5.59, lr=5e-5]Steps:  23%|‚ñà‚ñà‚ñé       | 23/100 [01:43<03:02,  2.37s/it, loss=5.59, loss_1=0.00169, loss_2=0.00233, loss_3=5.59, lr=5e-5]Steps:  23%|‚ñà‚ñà‚ñé       | 23/100 [01:43<03:02,  2.37s/it, loss=5.59, loss_1=0.000291, loss_2=0.000837, loss_3=5.59, lr=5e-5]Steps:  24%|‚ñà‚ñà‚ñç       | 24/100 [01:45<02:59,  2.36s/it, loss=5.59, loss_1=0.000291, loss_2=0.000837, loss_3=5.59, lr=5e-5]Steps:  24%|‚ñà‚ñà‚ñç       | 24/100 [01:45<02:59,  2.36s/it, loss=5.59, loss_1=4.54e-5, loss_2=0.000149, loss_3=5.59, lr=5e-5] Steps:  25%|‚ñà‚ñà‚ñå       | 25/100 [01:48<02:54,  2.33s/it, loss=5.59, loss_1=4.54e-5, loss_2=0.000149, loss_3=5.59, lr=5e-5]Steps:  25%|‚ñà‚ñà‚ñå       | 25/100 [01:48<02:54,  2.33s/it, loss=5.59, loss_1=0.000107, loss_2=0.000588, loss_3=5.59, lr=5e-5]Steps:  26%|‚ñà‚ñà‚ñå       | 26/100 [01:50<02:52,  2.34s/it, loss=5.59, loss_1=0.000107, loss_2=0.000588, loss_3=5.59, lr=5e-5]Steps:  26%|‚ñà‚ñà‚ñå       | 26/100 [01:50<02:52,  2.34s/it, loss=5.59, loss_1=0.000223, loss_2=0.00105, loss_3=5.59, lr=5e-5] Steps:  27%|‚ñà‚ñà‚ñã       | 27/100 [01:52<02:48,  2.31s/it, loss=5.59, loss_1=0.000223, loss_2=0.00105, loss_3=5.59, lr=5e-5]Steps:  27%|‚ñà‚ñà‚ñã       | 27/100 [01:52<02:48,  2.31s/it, loss=5.59, loss_1=6.76e-5, loss_2=0.000127, loss_3=5.59, lr=5e-5]Steps:  28%|‚ñà‚ñà‚ñä       | 28/100 [01:55<02:46,  2.31s/it, loss=5.59, loss_1=6.76e-5, loss_2=0.000127, loss_3=5.59, lr=5e-5]Steps:  28%|‚ñà‚ñà‚ñä       | 28/100 [01:55<02:46,  2.31s/it, loss=5.59, loss_1=0.000472, loss_2=0.00116, loss_3=5.58, lr=5e-5]Steps:  29%|‚ñà‚ñà‚ñâ       | 29/100 [01:57<02:43,  2.30s/it, loss=5.59, loss_1=0.000472, loss_2=0.00116, loss_3=5.58, lr=5e-5]Steps:  29%|‚ñà‚ñà‚ñâ       | 29/100 [01:57<02:43,  2.30s/it, loss=5.59, loss_1=0.000512, loss_2=0.00104, loss_3=5.58, lr=5e-5]Steps:  30%|‚ñà‚ñà‚ñà       | 30/100 [01:59<02:42,  2.32s/it, loss=5.59, loss_1=0.000512, loss_2=0.00104, loss_3=5.58, lr=5e-5]Steps:  30%|‚ñà‚ñà‚ñà       | 30/100 [01:59<02:42,  2.32s/it, loss=5.58, loss_1=0.000321, loss_2=0.000628, loss_3=5.58, lr=5e-5]Steps:  31%|‚ñà‚ñà‚ñà       | 31/100 [02:02<02:40,  2.33s/it, loss=5.58, loss_1=0.000321, loss_2=0.000628, loss_3=5.58, lr=5e-5]Steps:  31%|‚ñà‚ñà‚ñà       | 31/100 [02:02<02:40,  2.33s/it, loss=5.58, loss_1=5.2e-5, loss_2=0.000153, loss_3=5.58, lr=5e-5]  Steps:  32%|‚ñà‚ñà‚ñà‚ñè      | 32/100 [02:04<02:36,  2.30s/it, loss=5.58, loss_1=5.2e-5, loss_2=0.000153, loss_3=5.58, lr=5e-5]Steps:  32%|‚ñà‚ñà‚ñà‚ñè      | 32/100 [02:04<02:36,  2.30s/it, loss=5.58, loss_1=0.00037, loss_2=0.00074, loss_3=5.58, lr=5e-5]Steps:  33%|‚ñà‚ñà‚ñà‚ñé      | 33/100 [02:06<02:35,  2.32s/it, loss=5.58, loss_1=0.00037, loss_2=0.00074, loss_3=5.58, lr=5e-5]Steps:  33%|‚ñà‚ñà‚ñà‚ñé      | 33/100 [02:06<02:35,  2.32s/it, loss=5.58, loss_1=0.000651, loss_2=0.00201, loss_3=5.58, lr=5e-5]Steps:  34%|‚ñà‚ñà‚ñà‚ñç      | 34/100 [02:08<02:31,  2.30s/it, loss=5.58, loss_1=0.000651, loss_2=0.00201, loss_3=5.58, lr=5e-5]Steps:  34%|‚ñà‚ñà‚ñà‚ñç      | 34/100 [02:08<02:31,  2.30s/it, loss=5.58, loss_1=5.16e-5, loss_2=0.000108, loss_3=5.58, lr=5e-5]Steps:  35%|‚ñà‚ñà‚ñà‚ñå      | 35/100 [02:11<02:29,  2.30s/it, loss=5.58, loss_1=5.16e-5, loss_2=0.000108, loss_3=5.58, lr=5e-5]Steps:  35%|‚ñà‚ñà‚ñà‚ñå      | 35/100 [02:11<02:29,  2.30s/it, loss=5.58, loss_1=0.000591, loss_2=0.000911, loss_3=5.58, lr=5e-5]Steps:  36%|‚ñà‚ñà‚ñà‚ñå      | 36/100 [02:13<02:27,  2.30s/it, loss=5.58, loss_1=0.000591, loss_2=0.000911, loss_3=5.58, lr=5e-5]Steps:  36%|‚ñà‚ñà‚ñà‚ñå      | 36/100 [02:13<02:27,  2.30s/it, loss=5.58, loss_1=0.00116, loss_2=0.00262, loss_3=5.58, lr=5e-5]  Steps:  37%|‚ñà‚ñà‚ñà‚ñã      | 37/100 [02:15<02:25,  2.32s/it, loss=5.58, loss_1=0.00116, loss_2=0.00262, loss_3=5.58, lr=5e-5]Steps:  37%|‚ñà‚ñà‚ñà‚ñã      | 37/100 [02:15<02:25,  2.32s/it, loss=5.58, loss_1=0.000987, loss_2=0.00156, loss_3=5.58, lr=5e-5]Steps:  38%|‚ñà‚ñà‚ñà‚ñä      | 38/100 [02:18<02:22,  2.30s/it, loss=5.58, loss_1=0.000987, loss_2=0.00156, loss_3=5.58, lr=5e-5]Steps:  38%|‚ñà‚ñà‚ñà‚ñä      | 38/100 [02:18<02:22,  2.30s/it, loss=5.58, loss_1=0.000308, loss_2=0.00144, loss_3=5.58, lr=5e-5]Steps:  39%|‚ñà‚ñà‚ñà‚ñâ      | 39/100 [02:20<02:21,  2.32s/it, loss=5.58, loss_1=0.000308, loss_2=0.00144, loss_3=5.58, lr=5e-5]Steps:  39%|‚ñà‚ñà‚ñà‚ñâ      | 39/100 [02:20<02:21,  2.32s/it, loss=5.58, loss_1=0.00112, loss_2=0.0017, loss_3=5.58, lr=5e-5]  Steps:  40%|‚ñà‚ñà‚ñà‚ñà      | 40/100 [02:22<02:17,  2.30s/it, loss=5.58, loss_1=0.00112, loss_2=0.0017, loss_3=5.58, lr=5e-5]Steps:  40%|‚ñà‚ñà‚ñà‚ñà      | 40/100 [02:22<02:17,  2.30s/it, loss=5.58, loss_1=0.000855, loss_2=0.00188, loss_3=5.58, lr=5e-5]Steps:  41%|‚ñà‚ñà‚ñà‚ñà      | 41/100 [02:25<02:16,  2.31s/it, loss=5.58, loss_1=0.000855, loss_2=0.00188, loss_3=5.58, lr=5e-5]Steps:  41%|‚ñà‚ñà‚ñà‚ñà      | 41/100 [02:25<02:16,  2.31s/it, loss=5.58, loss_1=0.000977, loss_2=0.00151, loss_3=5.58, lr=5e-5]Steps:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/100 [02:27<02:12,  2.28s/it, loss=5.58, loss_1=0.000977, loss_2=0.00151, loss_3=5.58, lr=5e-5]Steps:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/100 [02:27<02:12,  2.28s/it, loss=5.58, loss_1=0.00111, loss_2=0.00109, loss_3=5.58, lr=5e-5] Steps:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 43/100 [02:29<02:12,  2.32s/it, loss=5.58, loss_1=0.00111, loss_2=0.00109, loss_3=5.58, lr=5e-5]Steps:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 43/100 [02:29<02:12,  2.32s/it, loss=5.58, loss_1=0.000449, loss_2=0.000625, loss_3=5.58, lr=5e-5]Steps:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 44/100 [02:31<02:08,  2.30s/it, loss=5.58, loss_1=0.000449, loss_2=0.000625, loss_3=5.58, lr=5e-5]Steps:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 44/100 [02:31<02:08,  2.30s/it, loss=5.58, loss_1=0.000279, loss_2=0.000992, loss_3=5.58, lr=5e-5]Steps:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 45/100 [02:34<02:07,  2.31s/it, loss=5.58, loss_1=0.000279, loss_2=0.000992, loss_3=5.58, lr=5e-5]Steps:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 45/100 [02:34<02:07,  2.31s/it, loss=5.58, loss_1=0.00124, loss_2=0.00144, loss_3=5.58, lr=5e-5]  Steps:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/100 [02:36<02:03,  2.29s/it, loss=5.58, loss_1=0.00124, loss_2=0.00144, loss_3=5.58, lr=5e-5]Steps:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/100 [02:36<02:03,  2.29s/it, loss=5.58, loss_1=0.000269, loss_2=0.00055, loss_3=5.57, lr=5e-5]Steps:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 47/100 [02:38<02:02,  2.31s/it, loss=5.58, loss_1=0.000269, loss_2=0.00055, loss_3=5.57, lr=5e-5]Steps:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 47/100 [02:38<02:02,  2.31s/it, loss=5.57, loss_1=4.44e-5, loss_2=0.000218, loss_3=5.57, lr=5e-5]Steps:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/100 [02:41<02:00,  2.33s/it, loss=5.57, loss_1=4.44e-5, loss_2=0.000218, loss_3=5.57, lr=5e-5]Steps:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/100 [02:41<02:00,  2.33s/it, loss=5.57, loss_1=0.000201, loss_2=0.000887, loss_3=5.57, lr=5e-5]Steps:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 49/100 [02:43<01:56,  2.29s/it, loss=5.57, loss_1=0.000201, loss_2=0.000887, loss_3=5.57, lr=5e-5]Steps:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 49/100 [02:43<01:56,  2.29s/it, loss=5.57, loss_1=6.45e-5, loss_2=0.00044, loss_3=5.57, lr=5e-5]  Steps:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 50/100 [02:45<01:56,  2.33s/it, loss=5.57, loss_1=6.45e-5, loss_2=0.00044, loss_3=5.57, lr=5e-5]Steps:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 50/100 [02:45<01:56,  2.33s/it, loss=5.57, loss_1=0.000179, loss_2=0.00045, loss_3=5.57, lr=5e-5]Steps:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 51/100 [02:48<01:52,  2.30s/it, loss=5.57, loss_1=0.000179, loss_2=0.00045, loss_3=5.57, lr=5e-5]Steps:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 51/100 [02:48<01:52,  2.30s/it, loss=5.57, loss_1=2.21e-5, loss_2=9.35e-5, loss_3=5.57, lr=5e-5] Steps:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/100 [02:50<01:51,  2.32s/it, loss=5.57, loss_1=2.21e-5, loss_2=9.35e-5, loss_3=5.57, lr=5e-5]Steps:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/100 [02:50<01:51,  2.32s/it, loss=5.57, loss_1=0.000709, loss_2=0.00198, loss_3=5.57, lr=5e-5]Steps:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 53/100 [02:52<01:47,  2.30s/it, loss=5.57, loss_1=0.000709, loss_2=0.00198, loss_3=5.57, lr=5e-5]Steps:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 53/100 [02:52<01:47,  2.30s/it, loss=5.57, loss_1=8.22e-5, loss_2=8.97e-5, loss_3=5.57, lr=5e-5] Steps:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 54/100 [02:55<01:46,  2.32s/it, loss=5.57, loss_1=8.22e-5, loss_2=8.97e-5, loss_3=5.57, lr=5e-5]Steps:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 54/100 [02:55<01:46,  2.32s/it, loss=5.57, loss_1=0.0001, loss_2=0.000105, loss_3=5.57, lr=5e-5]Steps:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 55/100 [02:57<01:43,  2.30s/it, loss=5.57, loss_1=0.0001, loss_2=0.000105, loss_3=5.57, lr=5e-5]Steps:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 55/100 [02:57<01:43,  2.30s/it, loss=5.57, loss_1=0.000316, loss_2=0.00106, loss_3=5.57, lr=5e-5]Steps:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 56/100 [02:59<01:41,  2.30s/it, loss=5.57, loss_1=0.000316, loss_2=0.00106, loss_3=5.57, lr=5e-5]Steps:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 56/100 [02:59<01:41,  2.30s/it, loss=5.57, loss_1=0.000119, loss_2=0.000325, loss_3=5.57, lr=5e-5]Steps:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 57/100 [03:01<01:38,  2.30s/it, loss=5.57, loss_1=0.000119, loss_2=0.000325, loss_3=5.57, lr=5e-5]Steps:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 57/100 [03:01<01:38,  2.30s/it, loss=5.57, loss_1=0.00122, loss_2=0.00146, loss_3=5.57, lr=5e-5]  Steps:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 58/100 [03:04<01:37,  2.32s/it, loss=5.57, loss_1=0.00122, loss_2=0.00146, loss_3=5.57, lr=5e-5]Steps:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 58/100 [03:04<01:37,  2.32s/it, loss=5.57, loss_1=0.000209, loss_2=0.0012, loss_3=5.57, lr=5e-5]Steps:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 59/100 [03:06<01:34,  2.29s/it, loss=5.57, loss_1=0.000209, loss_2=0.0012, loss_3=5.57, lr=5e-5]Steps:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 59/100 [03:06<01:34,  2.29s/it, loss=5.57, loss_1=0.000947, loss_2=0.00268, loss_3=5.57, lr=5e-5]Steps:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 60/100 [03:08<01:32,  2.31s/it, loss=5.57, loss_1=0.000947, loss_2=0.00268, loss_3=5.57, lr=5e-5]Steps:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 60/100 [03:08<01:32,  2.31s/it, loss=5.57, loss_1=0.00188, loss_2=0.00221, loss_3=5.57, lr=5e-5] Steps:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 61/100 [03:11<01:29,  2.29s/it, loss=5.57, loss_1=0.00188, loss_2=0.00221, loss_3=5.57, lr=5e-5]Steps:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 61/100 [03:11<01:29,  2.29s/it, loss=5.57, loss_1=0.0011, loss_2=0.00219, loss_3=5.57, lr=5e-5] Steps:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/100 [03:13<01:27,  2.31s/it, loss=5.57, loss_1=0.0011, loss_2=0.00219, loss_3=5.57, lr=5e-5]Steps:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/100 [03:13<01:27,  2.31s/it, loss=5.57, loss_1=0.000363, loss_2=0.000831, loss_3=5.57, lr=5e-5]Steps:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 63/100 [03:15<01:25,  2.31s/it, loss=5.57, loss_1=0.000363, loss_2=0.000831, loss_3=5.57, lr=5e-5]Steps:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 63/100 [03:15<01:25,  2.31s/it, loss=5.57, loss_1=0.000468, loss_2=0.000871, loss_3=5.57, lr=5e-5]Steps:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 64/100 [03:18<01:23,  2.31s/it, loss=5.57, loss_1=0.000468, loss_2=0.000871, loss_3=5.57, lr=5e-5]Steps:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 64/100 [03:18<01:23,  2.31s/it, loss=5.57, loss_1=2.26e-5, loss_2=0.000141, loss_3=5.56, lr=5e-5] Steps:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 65/100 [03:20<01:21,  2.32s/it, loss=5.57, loss_1=2.26e-5, loss_2=0.000141, loss_3=5.56, lr=5e-5]Steps:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 65/100 [03:20<01:21,  2.32s/it, loss=5.57, loss_1=0.000575, loss_2=0.00159, loss_3=5.56, lr=5e-5]Steps:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/100 [03:22<01:18,  2.30s/it, loss=5.57, loss_1=0.000575, loss_2=0.00159, loss_3=5.56, lr=5e-5]Steps:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/100 [03:22<01:18,  2.30s/it, loss=5.57, loss_1=0.00146, loss_2=0.00136, loss_3=5.56, lr=5e-5] Steps:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 67/100 [03:25<01:16,  2.32s/it, loss=5.57, loss_1=0.00146, loss_2=0.00136, loss_3=5.56, lr=5e-5]Steps:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 67/100 [03:25<01:16,  2.32s/it, loss=5.57, loss_1=0.00206, loss_2=0.00247, loss_3=5.56, lr=5e-5]Steps:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 68/100 [03:27<01:13,  2.30s/it, loss=5.57, loss_1=0.00206, loss_2=0.00247, loss_3=5.56, lr=5e-5]Steps:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 68/100 [03:27<01:13,  2.30s/it, loss=5.57, loss_1=0.00169, loss_2=0.00374, loss_3=5.56, lr=5e-5]Steps:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 69/100 [03:29<01:11,  2.32s/it, loss=5.57, loss_1=0.00169, loss_2=0.00374, loss_3=5.56, lr=5e-5]Steps:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 69/100 [03:29<01:11,  2.32s/it, loss=5.56, loss_1=0.000381, loss_2=0.000834, loss_3=5.56, lr=5e-5]Steps:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 70/100 [03:31<01:08,  2.28s/it, loss=5.56, loss_1=0.000381, loss_2=0.000834, loss_3=5.56, lr=5e-5]Steps:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 70/100 [03:31<01:08,  2.28s/it, loss=5.56, loss_1=0.000441, loss_2=0.00217, loss_3=5.56, lr=5e-5] Steps:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 71/100 [03:34<01:07,  2.32s/it, loss=5.56, loss_1=0.000441, loss_2=0.00217, loss_3=5.56, lr=5e-5]Steps:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 71/100 [03:34<01:07,  2.32s/it, loss=5.56, loss_1=0.000257, loss_2=0.000454, loss_3=5.56, lr=5e-5]Steps:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/100 [03:36<01:04,  2.30s/it, loss=5.56, loss_1=0.000257, loss_2=0.000454, loss_3=5.56, lr=5e-5]Steps:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/100 [03:36<01:04,  2.30s/it, loss=5.56, loss_1=2.08e-5, loss_2=6.15e-5, loss_3=5.56, lr=5e-5]  Steps:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 73/100 [03:38<01:02,  2.32s/it, loss=5.56, loss_1=2.08e-5, loss_2=6.15e-5, loss_3=5.56, lr=5e-5]Steps:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 73/100 [03:38<01:02,  2.32s/it, loss=5.56, loss_1=0.000786, loss_2=0.00219, loss_3=5.56, lr=5e-5]Steps:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 74/100 [03:41<00:59,  2.30s/it, loss=5.56, loss_1=0.000786, loss_2=0.00219, loss_3=5.56, lr=5e-5]Steps:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 74/100 [03:41<00:59,  2.30s/it, loss=5.56, loss_1=8.73e-5, loss_2=0.000689, loss_3=5.56, lr=5e-5]Steps:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 75/100 [03:43<00:57,  2.31s/it, loss=5.56, loss_1=8.73e-5, loss_2=0.000689, loss_3=5.56, lr=5e-5]Steps:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 75/100 [03:43<00:57,  2.31s/it, loss=5.56, loss_1=0.00177, loss_2=0.00223, loss_3=5.56, lr=5e-5] Steps:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/100 [03:45<00:55,  2.29s/it, loss=5.56, loss_1=0.00177, loss_2=0.00223, loss_3=5.56, lr=5e-5]Steps:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/100 [03:45<00:55,  2.29s/it, loss=5.56, loss_1=0.00103, loss_2=0.00129, loss_3=5.56, lr=5e-5]Steps:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 77/100 [03:48<00:52,  2.30s/it, loss=5.56, loss_1=0.00103, loss_2=0.00129, loss_3=5.56, lr=5e-5]Steps:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 77/100 [03:48<00:52,  2.30s/it, loss=5.56, loss_1=0.00117, loss_2=0.00171, loss_3=5.56, lr=5e-5]05/28/2024 03:34:30 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: a sks dog in crt style.
{'image_encoder', 'feature_extractor'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][A{'timestep_type', 'sigma_min', 'sigma_max'} was not found in config. Values will be initialized to default values.
Loaded scheduler as EulerDiscreteScheduler from `scheduler` subfolder of stabilityai/stable-diffusion-xl-base-1.0.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of stabilityai/stable-diffusion-xl-base-1.0.
Loaded tokenizer_2 as CLIPTokenizer from `tokenizer_2` subfolder of stabilityai/stable-diffusion-xl-base-1.0.
Loading pipeline components...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 72.01it/s]
{'solver_order', 'variance_type', 'dynamic_thresholding_ratio', 'lambda_min_clipped', 'algorithm_type', 'solver_type', 'lower_order_final', 'use_lu_lambdas', 'euler_at_final', 'thresholding'} was not found in config. Values will be initialized to default values.
Steps:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 78/100 [04:38<06:08, 16.73s/it, loss=5.56, loss_1=0.00117, loss_2=0.00171, loss_3=5.56, lr=5e-5]Steps:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 78/100 [04:38<06:08, 16.73s/it, loss=5.56, loss_1=4.56e-5, loss_2=0.000103, loss_3=5.56, lr=5e-5]Steps:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 79/100 [04:40<04:20, 12.38s/it, loss=5.56, loss_1=4.56e-5, loss_2=0.000103, loss_3=5.56, lr=5e-5]Steps:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 79/100 [04:40<04:20, 12.38s/it, loss=5.56, loss_1=0.000128, loss_2=0.000686, loss_3=5.56, lr=5e-5]Steps:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 80/100 [04:43<03:07,  9.38s/it, loss=5.56, loss_1=0.000128, loss_2=0.000686, loss_3=5.56, lr=5e-5]Steps:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 80/100 [04:43<03:07,  9.38s/it, loss=5.56, loss_1=0.000129, loss_2=0.000237, loss_3=5.56, lr=5e-5]Steps:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 81/100 [04:45<02:17,  7.24s/it, loss=5.56, loss_1=0.000129, loss_2=0.000237, loss_3=5.56, lr=5e-5]Steps:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 81/100 [04:45<02:17,  7.24s/it, loss=5.56, loss_1=0.000121, loss_2=0.000118, loss_3=5.56, lr=5e-5]Steps:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 82/100 [04:47<01:43,  5.77s/it, loss=5.56, loss_1=0.000121, loss_2=0.000118, loss_3=5.56, lr=5e-5]Steps:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 82/100 [04:47<01:43,  5.77s/it, loss=5.56, loss_1=0.000521, loss_2=0.000913, loss_3=5.55, lr=5e-5]Steps:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 83/100 [04:49<01:20,  4.72s/it, loss=5.56, loss_1=0.000521, loss_2=0.000913, loss_3=5.55, lr=5e-5]Steps:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 83/100 [04:49<01:20,  4.72s/it, loss=5.56, loss_1=0.00102, loss_2=0.00306, loss_3=5.55, lr=5e-5]  Steps:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 84/100 [04:52<01:03,  4.00s/it, loss=5.56, loss_1=0.00102, loss_2=0.00306, loss_3=5.55, lr=5e-5]Steps:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 84/100 [04:52<01:03,  4.00s/it, loss=5.56, loss_1=0.00177, loss_2=0.00232, loss_3=5.55, lr=5e-5]Steps:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 85/100 [04:54<00:52,  3.49s/it, loss=5.56, loss_1=0.00177, loss_2=0.00232, loss_3=5.55, lr=5e-5]Steps:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 85/100 [04:54<00:52,  3.49s/it, loss=5.55, loss_1=0.00012, loss_2=0.000809, loss_3=5.55, lr=5e-5]Steps:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/100 [04:56<00:44,  3.15s/it, loss=5.55, loss_1=0.00012, loss_2=0.000809, loss_3=5.55, lr=5e-5]Steps:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/100 [04:56<00:44,  3.15s/it, loss=5.55, loss_1=0.00116, loss_2=0.00117, loss_3=5.55, lr=5e-5] Steps:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 87/100 [04:59<00:37,  2.87s/it, loss=5.55, loss_1=0.00116, loss_2=0.00117, loss_3=5.55, lr=5e-5]Steps:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 87/100 [04:59<00:37,  2.87s/it, loss=5.55, loss_1=0.000538, loss_2=0.00134, loss_3=5.55, lr=5e-5]Steps:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 88/100 [05:01<00:32,  2.72s/it, loss=5.55, loss_1=0.000538, loss_2=0.00134, loss_3=5.55, lr=5e-5]Steps:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 88/100 [05:01<00:32,  2.72s/it, loss=5.55, loss_1=6.15e-5, loss_2=0.000127, loss_3=5.55, lr=5e-5]Steps:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 89/100 [05:03<00:28,  2.58s/it, loss=5.55, loss_1=6.15e-5, loss_2=0.000127, loss_3=5.55, lr=5e-5]Steps:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 89/100 [05:03<00:28,  2.58s/it, loss=5.55, loss_1=8.43e-5, loss_2=0.000255, loss_3=5.55, lr=5e-5]Steps:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 90/100 [05:06<00:25,  2.51s/it, loss=5.55, loss_1=8.43e-5, loss_2=0.000255, loss_3=5.55, lr=5e-5]Steps:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 90/100 [05:06<00:25,  2.51s/it, loss=5.55, loss_1=0.00189, loss_2=0.00247, loss_3=5.55, lr=5e-5] Steps:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 91/100 [05:08<00:22,  2.45s/it, loss=5.55, loss_1=0.00189, loss_2=0.00247, loss_3=5.55, lr=5e-5]Steps:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 91/100 [05:08<00:22,  2.45s/it, loss=5.55, loss_1=0.00138, loss_2=0.00256, loss_3=5.55, lr=5e-5]Steps:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 92/100 [05:10<00:19,  2.40s/it, loss=5.55, loss_1=0.00138, loss_2=0.00256, loss_3=5.55, lr=5e-5]Steps:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 92/100 [05:10<00:19,  2.40s/it, loss=5.55, loss_1=0.00222, loss_2=0.00188, loss_3=5.55, lr=5e-5]Steps:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 93/100 [05:13<00:16,  2.39s/it, loss=5.55, loss_1=0.00222, loss_2=0.00188, loss_3=5.55, lr=5e-5]Steps:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 93/100 [05:13<00:16,  2.39s/it, loss=5.55, loss_1=0.00115, loss_2=0.00312, loss_3=5.55, lr=5e-5]Steps:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 94/100 [05:15<00:14,  2.35s/it, loss=5.55, loss_1=0.00115, loss_2=0.00312, loss_3=5.55, lr=5e-5]Steps:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 94/100 [05:15<00:14,  2.35s/it, loss=5.55, loss_1=0.000585, loss_2=0.000978, loss_3=5.55, lr=5e-5]Steps:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 95/100 [05:17<00:11,  2.35s/it, loss=5.55, loss_1=0.000585, loss_2=0.000978, loss_3=5.55, lr=5e-5]Steps:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 95/100 [05:17<00:11,  2.35s/it, loss=5.55, loss_1=0.000819, loss_2=0.00189, loss_3=5.55, lr=5e-5] Steps:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/100 [05:19<00:09,  2.32s/it, loss=5.55, loss_1=0.000819, loss_2=0.00189, loss_3=5.55, lr=5e-5]Steps:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/100 [05:19<00:09,  2.32s/it, loss=5.55, loss_1=7.58e-5, loss_2=0.000179, loss_3=5.55, lr=5e-5]Steps:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 97/100 [05:22<00:06,  2.33s/it, loss=5.55, loss_1=7.58e-5, loss_2=0.000179, loss_3=5.55, lr=5e-5]Steps:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 97/100 [05:22<00:06,  2.33s/it, loss=5.55, loss_1=0.000217, loss_2=0.00152, loss_3=5.55, lr=5e-5]Steps:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 98/100 [05:24<00:04,  2.29s/it, loss=5.55, loss_1=0.000217, loss_2=0.00152, loss_3=5.55, lr=5e-5]Steps:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 98/100 [05:24<00:04,  2.29s/it, loss=5.55, loss_1=0.000912, loss_2=0.00156, loss_3=5.55, lr=5e-5]Steps:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 99/100 [05:26<00:02,  2.32s/it, loss=5.55, loss_1=0.000912, loss_2=0.00156, loss_3=5.55, lr=5e-5]Steps:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 99/100 [05:26<00:02,  2.32s/it, loss=5.55, loss_1=9.33e-5, loss_2=0.000248, loss_3=5.55, lr=5e-5]Steps: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [05:29<00:00,  2.33s/it, loss=5.55, loss_1=9.33e-5, loss_2=0.000248, loss_3=5.55, lr=5e-5]Steps: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [05:29<00:00,  2.33s/it, loss=5.55, loss_1=0.000892, loss_2=0.00397, loss_3=5.54, lr=5e-5]Model weights saved in ./models/ziplora_style1_dog3_2024-05-28_03-29-59/pytorch_lora_weights.safetensors
{'image_encoder', 'feature_extractor'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][A{'timestep_type', 'sigma_min', 'sigma_max'} was not found in config. Values will be initialized to default values.
Loaded scheduler as EulerDiscreteScheduler from `scheduler` subfolder of stabilityai/stable-diffusion-xl-base-1.0.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of stabilityai/stable-diffusion-xl-base-1.0.
Loaded text_encoder_2 as CLIPTextModelWithProjection from `text_encoder_2` subfolder of stabilityai/stable-diffusion-xl-base-1.0.

Loading pipeline components...:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.36it/s][ALoaded tokenizer_2 as CLIPTokenizer from `tokenizer_2` subfolder of stabilityai/stable-diffusion-xl-base-1.0.
{'dropout', 'reverse_transformer_layers_per_block', 'attention_type'} was not found in config. Values will be initialized to default values.
Loaded unet as UNet2DConditionModel from `unet` subfolder of stabilityai/stable-diffusion-xl-base-1.0.

Loading pipeline components...:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:09<00:01,  1.94s/it][ALoaded text_encoder as CLIPTextModel from `text_encoder` subfolder of stabilityai/stable-diffusion-xl-base-1.0.

Loading pipeline components...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:10<00:00,  1.60s/it][ALoading pipeline components...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:10<00:00,  1.47s/it]
{'solver_order', 'variance_type', 'dynamic_thresholding_ratio', 'lambda_min_clipped', 'algorithm_type', 'solver_type', 'lower_order_final', 'use_lu_lambdas', 'euler_at_final', 'thresholding'} was not found in config. Values will be initialized to default values.

  0%|          | 0/25 [00:00<?, ?it/s][A
  4%|‚ñç         | 1/25 [00:00<00:05,  4.53it/s][A
  8%|‚ñä         | 2/25 [00:00<00:03,  6.37it/s][A
 12%|‚ñà‚ñè        | 3/25 [00:00<00:03,  6.95it/s][A
 16%|‚ñà‚ñå        | 4/25 [00:00<00:02,  7.27it/s][A
 20%|‚ñà‚ñà        | 5/25 [00:00<00:02,  7.46it/s][A
 24%|‚ñà‚ñà‚ñç       | 6/25 [00:00<00:02,  7.57it/s][A
 28%|‚ñà‚ñà‚ñä       | 7/25 [00:00<00:02,  7.65it/s][A
 32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:01<00:02,  7.70it/s][A
 36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:01<00:02,  7.73it/s][A
 40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:01<00:01,  7.76it/s][A
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:01<00:01,  7.77it/s][A
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:01<00:01,  7.79it/s][A
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:01<00:01,  7.79it/s][A
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:01<00:01,  7.80it/s][A
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:01<00:01,  7.80it/s][A
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:02<00:01,  7.80it/s][A
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:02<00:01,  7.81it/s][A
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:02<00:00,  7.81it/s][A
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:02<00:00,  7.81it/s][A
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:02<00:00,  7.81it/s][A
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:02<00:00,  7.81it/s][A
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:02<00:00,  7.79it/s][A
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:03<00:00,  7.80it/s][A
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:03<00:00,  7.66it/s][A
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:03<00:00,  7.85it/s][A100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:03<00:00,  7.62it/s]

  0%|          | 0/25 [00:00<?, ?it/s][A
  4%|‚ñç         | 1/25 [00:00<00:03,  7.73it/s][A
 12%|‚ñà‚ñè        | 3/25 [00:00<00:02,  8.74it/s][A
 16%|‚ñà‚ñå        | 4/25 [00:00<00:02,  8.40it/s][A
 20%|‚ñà‚ñà        | 5/25 [00:00<00:02,  8.20it/s][A
 24%|‚ñà‚ñà‚ñç       | 6/25 [00:00<00:02,  8.07it/s][A
 28%|‚ñà‚ñà‚ñä       | 7/25 [00:00<00:02,  7.99it/s][A
 32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:00<00:02,  7.92it/s][A
 36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:01<00:02,  7.89it/s][A
 40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:01<00:01,  7.87it/s][A
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:01<00:01,  7.84it/s][A
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:01<00:01,  7.83it/s][A
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:01<00:01,  7.82it/s][A
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:01<00:01,  7.82it/s][A
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:01<00:01,  7.82it/s][A
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:02<00:01,  7.82it/s][A
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:02<00:01,  7.82it/s][A
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:02<00:00,  7.82it/s][A
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:02<00:00,  7.80it/s][A
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:02<00:00,  7.81it/s][A
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:02<00:00,  7.81it/s][A
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:02<00:00,  7.81it/s][A
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:02<00:00,  7.81it/s][A
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:03<00:00,  7.81it/s][A
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:03<00:00,  7.81it/s][A100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:03<00:00,  7.90it/s]

  0%|          | 0/25 [00:00<?, ?it/s][A
  4%|‚ñç         | 1/25 [00:00<00:03,  7.73it/s][A
 12%|‚ñà‚ñè        | 3/25 [00:00<00:02,  8.73it/s][A
 16%|‚ñà‚ñå        | 4/25 [00:00<00:02,  8.39it/s][A
 20%|‚ñà‚ñà        | 5/25 [00:00<00:02,  8.19it/s][A
 24%|‚ñà‚ñà‚ñç       | 6/25 [00:00<00:02,  8.06it/s][A
 28%|‚ñà‚ñà‚ñä       | 7/25 [00:00<00:02,  7.98it/s][A
 32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:00<00:02,  7.93it/s][A
 36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:01<00:02,  7.88it/s][A
 40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:01<00:01,  7.86it/s][A
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:01<00:01,  7.83it/s][A
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:01<00:01,  7.83it/s][A
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:01<00:01,  7.81it/s][A
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:01<00:01,  7.79it/s][A
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:01<00:01,  7.79it/s][A
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:02<00:01,  7.79it/s][A
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:02<00:01,  7.79it/s][A
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:02<00:00,  7.78it/s][A
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:02<00:00,  7.79it/s][A
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:02<00:00,  7.78it/s][A
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:02<00:00,  7.79it/s][A
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:02<00:00,  7.78it/s][A
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:02<00:00,  7.78it/s][A
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:03<00:00,  7.78it/s][A
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:03<00:00,  7.77it/s][A100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:03<00:00,  7.88it/s]

  0%|          | 0/25 [00:00<?, ?it/s][A
  4%|‚ñç         | 1/25 [00:00<00:03,  7.74it/s][A
 12%|‚ñà‚ñè        | 3/25 [00:00<00:02,  8.72it/s][A
 16%|‚ñà‚ñå        | 4/25 [00:00<00:02,  8.38it/s][A
 20%|‚ñà‚ñà        | 5/25 [00:00<00:02,  8.17it/s][A
 24%|‚ñà‚ñà‚ñç       | 6/25 [00:00<00:02,  8.05it/s][A
 28%|‚ñà‚ñà‚ñä       | 7/25 [00:00<00:02,  7.98it/s][A
 32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:00<00:02,  7.91it/s][A
 36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:01<00:02,  7.87it/s][A
 40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:01<00:01,  7.85it/s][A
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:01<00:01,  7.84it/s][A
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:01<00:01,  7.82it/s][A
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:01<00:01,  7.82it/s][A
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:01<00:01,  7.80it/s][A
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:01<00:01,  7.81it/s][A
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:02<00:01,  7.80it/s][A
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:02<00:01,  7.78it/s][A
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:02<00:00,  7.80it/s][A
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:02<00:00,  7.79it/s][A
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:02<00:00,  7.80it/s][A
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:02<00:00,  7.78it/s][A
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:02<00:00,  7.79it/s][A
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:02<00:00,  7.80it/s][A
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:03<00:00,  7.79it/s][A
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:03<00:00,  7.78it/s][A100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:03<00:00,  7.88it/s]
wandb: - 7.338 MB of 11.374 MB uploadedwandb: \ 7.338 MB of 11.374 MB uploadedwandb: | 11.386 MB of 11.401 MB uploadedwandb: / 11.386 MB of 11.401 MB uploadedwandb: - 11.386 MB of 11.401 MB uploadedwandb: \ 11.401 MB of 11.401 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:   loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb: loss_1 ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñÉ‚ñá‚ñÅ‚ñÅ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÅ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÖ‚ñÅ‚ñÉ‚ñá‚ñÉ‚ñÅ‚ñà‚ñÉ‚ñÇ‚ñÑ
wandb: loss_2 ‚ñÅ‚ñÅ‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÖ‚ñÅ‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÇ‚ñÉ‚ñÖ‚ñÉ‚ñÅ‚ñÑ‚ñÉ‚ñÑ‚ñà
wandb: loss_3 ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:     lr ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   loss 5.54968
wandb: loss_1 0.00089
wandb: loss_2 0.00397
wandb: loss_3 5.54482
wandb:     lr 5e-05
wandb: 
wandb: üöÄ View run swept-armadillo-1 at: https://wandb.ai/salbowic-org/dreambooth-ziplora-sd-xl/runs/q1338fxq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/salbowic-org/dreambooth-ziplora-sd-xl
wandb: Synced 6 W&B file(s), 12 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240528_033039-q1338fxq/logs
/net/tscratch/people/plgas2000/.conda/envs/myenv2/lib/python3.9/site-packages/wandb/sdk/wandb_run.py:2265: UserWarning: Run (q1338fxq) is finished. The call to `_console_raw_callback` will be ignored. Please make sure that you are using an active run.
  lambda data: self._console_raw_callback("stderr", data),
Steps: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [06:12<00:00,  3.72s/it, loss=5.55, loss_1=0.000892, loss_2=0.00397, loss_3=5.54, lr=5e-5]
